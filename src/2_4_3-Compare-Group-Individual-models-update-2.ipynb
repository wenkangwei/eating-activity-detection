{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.3 Compare Group individual models Version 2 with format updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from dataset import create_train_test_file_list, Person_MealsDataset, balance_data_indices\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "### imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Turn off TensorFlow logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "import loadfile\n",
    "import addons\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Input, add\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.models import load_model, save_model, Model\n",
    "\n",
    "\n",
    "from dataset import create_train_test_file_list, Person_MealsDataset, balance_data_indices\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shimmer_global_mean = [-0.012359981,-0.0051663737,0.011612018,\n",
    "                        0.05796114,0.1477952,-0.034395125 ]\n",
    "\n",
    "shimmer_global_stddev = [0.05756385,0.040893298,0.043825723,\n",
    "                        17.199743,15.311142,21.229317 ]\n",
    "\n",
    "shimmer_trended_mean = [-0.000002,-0.000002,-0.000000,\n",
    "                0.058144,0.147621,-0.033260 ]\n",
    "\n",
    "shimmer_trended_stddev = [0.037592,0.034135,0.032263,\n",
    "                17.209038,15.321441,21.242532 ]\n",
    "\n",
    "all_zero_means = [0,0,0,0,0,0]\n",
    "\n",
    "meanvals = all_zero_means\n",
    "stdvals = shimmer_trended_stddev\n",
    "\n",
    "\n",
    "random_seed  = 1000\n",
    "seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed= 1000):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(seed= random_seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acti_model(input_shape):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv1D(10, 44, strides=2,activation='relu', input_shape=input_shape))\n",
    "        model.add(Conv1D(10, 20, strides=2, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
    "        model.add(Conv1D(10, 4, strides=2, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "def residual_module(layer_in, n_filters):\n",
    "            merge_input = layer_in\n",
    "            # check if the number of filters needs to be increase, assumes channels last format\n",
    "            if layer_in.shape[-1] != n_filters:\n",
    "                merge_input = Conv1D(n_filters, (1,), padding='same', kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l1(0.01))(layer_in)\n",
    "            # conv1\n",
    "            # L2 for avoiding overfitting\n",
    "            conv1 = Conv1D(n_filters, (5,), padding='same', kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01))(layer_in)\n",
    "            # Batch normal for re-scaling data and better fit data\n",
    "            conv1 = tf.keras.layers.BatchNormalization(1)(conv1)\n",
    "            conv1 = tf.keras.layers.ReLU()(conv1)\n",
    "            # conv2\n",
    "            conv2 = Conv1D(n_filters, (5,), padding='same', kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01))(conv1)\n",
    "            conv2 = tf.keras.layers.BatchNormalization(1)(conv2)\n",
    "            \n",
    "            # add filters, assumes filters/channels last\n",
    "            #out = conv2\n",
    "            out = add([conv2, merge_input])\n",
    "            # activation function\n",
    "            layer_out = Activation('relu')(out)\n",
    "            return layer_out\n",
    "        \n",
    "\n",
    "def res_model(input_shape):\n",
    "            in_layer = Input(shape = input_shape)\n",
    "            out = Conv1D(10, 40, strides=2)(in_layer)\n",
    "            out = residual_module(layer_in= out,  n_filters=10)\n",
    "            out = residual_module(layer_in= out,  n_filters=10)\n",
    "            out = GlobalAveragePooling1D()(out)\n",
    "            # L1 for feature selection\n",
    "            out = Dense(200, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01))(out)\n",
    "            out = Dense(1, activation='sigmoid')(out)\n",
    "            model = Model(inputs=in_layer, outputs=out)\n",
    "            return model\n",
    "        \n",
    "def transfer_model(input_shape, tf_model):\n",
    "            in_layer = Input(shape = input_shape)\n",
    "            out = tf_model(in_layer)\n",
    "            out = Dense(1, activation='sigmoid')(out)\n",
    "            model = Model(inputs=in_layer, outputs=out)\n",
    "            return model\n",
    "    \n",
    "    \n",
    "    \n",
    "def transfer_model_v2(input_shape, tf_model):\n",
    "            in_layer = Input(shape = input_shape)\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(in_layer)\n",
    "            for layer in tf_model.layers[1:-1]:  # 跳过最后一层 \n",
    "                model.add(layer)\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            return model\n",
    "    \n",
    "# newmodel = my_model(input_shape =(900,6) )\n",
    "\n",
    "# newmodel.compile(loss='binary_crossentropy',\n",
    "#                 optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataset import create_train_test_file_list,  balance_data_indices  #Person_MealsDataset,\n",
    "from utils import *\n",
    "from model import *\n",
    "def train_models(model, win_ls = [],EPOCHS = 10,stridesec = 1,name = \"wenkanw\",model_name=\"v2\" ,random_seed= 1000, split_day=False,test_balanced=False):\n",
    "    \n",
    "    from datetime  import datetime\n",
    "    batch_size = 128\n",
    "    outfile = sys.stdout\n",
    "    perf = {\"model\":[],\"win(sec)\":[], \"acc\":[],\"recall\":[], \"auc\":[]}\n",
    "    model_ls = []\n",
    "    hist_ls = []\n",
    "    seed_everything(seed= random_seed) \n",
    "    for winsize in win_ls:\n",
    "        winmin = winsize\n",
    "        winlength = int(winmin * 60 * 15)\n",
    "        step = int(stridesec * 15)\n",
    "        start_time = datetime.now()\n",
    "        arr = [\"echo -n 'PBS: node is '; cat $PBS_NODEFILE\",\\\n",
    "              \"echo PBS: job identifier is $PBS_JOBID\",\\\n",
    "              \"echo PBS: job name is $PBS_JOBNAME\"]\n",
    "        [os.system(cmd) for cmd in arr]\n",
    "        print(\"*****************************************************************\\n\", file=outfile, flush=True)\n",
    "        print(\"Execution Started at \" + start_time.strftime(\"%m/%d/%Y, %H:%M:%S\"), file=outfile, flush=True)\n",
    "        print(\"WindowLength: {:.2f} min ({:d} datum)\\tSlide: {:d} ({:d} datum)\\tEpochs:{:d}\\n\".format(winmin, winlength, stridesec, step, EPOCHS), file=outfile, flush=True)\n",
    "\n",
    "\n",
    "        pathtemp = \"../models/\" + name+\"_models\" +\"/\"+model_name+\"_M_F_\"\n",
    "        #pathtemp = \"../models/\" + name +\"/\"+model_name+\"_M_F_\"\n",
    "        modelpath = pathtemp + \"{:f}Min.h5\".format(winmin)\n",
    "        jsonpath = pathtemp + \"{:f}Min.json\".format(winmin)\n",
    "        print(\"Model to Save: \",modelpath)\n",
    "        print()\n",
    "        # Load the dataset\n",
    "        \n",
    "        person = name\n",
    "        if split_day:\n",
    "            pathtemp = \"../models/\" + name+\"_models\" +\"/\"+model_name+\"_split_day_M_F_\"\n",
    "            modelpath = pathtemp + \"{:f}Min.h5\".format(winmin)\n",
    "            jsonpath = pathtemp + \"{:f}Min.json\".format(winmin)\n",
    "            create_train_test_file_list(file_name= \"all_files_list.txt\",person_name =name,\n",
    "                         out_path = \"../data-file-indices/\",root_path= \"../\",\n",
    "                         test_ratio = 0.2, print_flag = True, shuffle=True, random_state=random_seed)\n",
    "\n",
    "            meal_data_train = Person_MealsDataset(person_name= person, file_name = \"train_files\", winmin = winmin,stridesec = stridesec)\n",
    "            meal_data_test = Person_MealsDataset(person_name= person, file_name = \"test_files\", winmin = winmin,stridesec = stridesec)\n",
    "\n",
    "            train_indices, valid_indices = split_train_test_indices(X= [i for i in range(len(meal_data_train.labels))],\n",
    "                                                                    y = meal_data_train.labels, test_size = 0.2,\n",
    "                                                                   random_seed = random_seed)\n",
    "            #balanced train set\n",
    "            trainset_labels = meal_data_train.labels[train_indices]\n",
    "            train_indices = balance_data_indices(trainset_labels,data_indices= train_indices,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "\n",
    "            # balance test set\n",
    "            testset_labels = meal_data_test.labels\n",
    "            if test_balanced:\n",
    "                test_indices = balance_data_indices(testset_labels,data_indices=[i for i in range(len(meal_data_test))] ,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "            else:\n",
    "                # without balancing data\n",
    "                test_indices = [i for i in range(len(meal_data_test))] \n",
    "            # get numpy dataset\n",
    "            balancedData, balancedLabels = meal_data_train.get_subset(train_indices)\n",
    "            valid_balancedData, valid_balancedLabels = meal_data_train.get_subset(valid_indices)\n",
    "            test_Data, test_Labels = meal_data_test.get_subset(test_indices)\n",
    "\n",
    "        else:\n",
    "        \n",
    "            meal_data = Person_MealsDataset(person_name= person, file_name = \"all_files_list\", winmin = winmin,stridesec = stridesec)\n",
    "            samples,labels =  meal_data.data_indices, meal_data.labels\n",
    "            # split train set and test set\n",
    "            train_indices, test_indices = split_train_test_indices(X= [i for i in range(len(labels))],\n",
    "                                                                    y = labels, test_size = 0.2,\n",
    "                                                                   random_seed = random_seed)\n",
    "            # balance train set\n",
    "            trainset_labels = labels[train_indices]\n",
    "            train_indices_balanced = balance_data_indices(trainset_labels,data_indices= train_indices,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "            #balance test set\n",
    "            testset_labels = labels[test_indices]\n",
    "            if test_balanced:\n",
    "                test_indices = balance_data_indices(testset_labels,data_indices= test_indices,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "            else:\n",
    "                test_indices = [i for i in range(len(meal_data_test))] \n",
    "            train_set_balanced = torch.utils.data.Subset(meal_data, train_indices_balanced)\n",
    "            test_set = torch.utils.data.Subset(meal_data, test_indices)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(train_set_balanced,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "            test_loader = torch.utils.data.DataLoader(test_set ,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "            print(\"Data Loader Created\")            \n",
    "            \n",
    "            # split validation set\n",
    "            balanced_trainset_labels = labels[train_indices_balanced]\n",
    "            train_indices, valid_indices = split_train_test_indices(X= train_indices_balanced,\n",
    "                                                                    y = balanced_trainset_labels, test_size = 0.2,\n",
    "                                                                   random_seed = random_seed)\n",
    "            valid_set_balanced = torch.utils.data.Subset(meal_data, valid_indices)\n",
    "            valid_loader = torch.utils.data.DataLoader(valid_set_balanced,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "            balancedData, balancedLabels = meal_data.get_subset(train_indices)\n",
    "            valid_balancedData, valid_balancedLabels = meal_data.get_subset(valid_indices)\n",
    "            test_Data, test_Labels = meal_data.get_subset(test_indices)\n",
    "        \n",
    "\n",
    "        #training settings\n",
    "        mcp_save = tf.keras.callbacks.ModelCheckpoint(modelpath, save_best_only=True, monitor='accuracy')\n",
    "        \n",
    "\n",
    "        scheduler = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=3, verbose=0,\n",
    "                                             mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.)\n",
    "        #train model\n",
    "        H = model.fit(x=balancedData, y = balancedLabels,\n",
    "                       validation_data=(valid_balancedData, valid_balancedLabels),\n",
    "                    epochs = EPOCHS, batch_size=batch_size, verbose=1,\n",
    "                    callbacks=[mcp_save,scheduler]) # removed addons.LossHistory(jsonpath) for compatibility with TensorFlow 2.2.0, needs to be re-added at some point\n",
    "\n",
    "        print(\"Max value: \", max(H.history['accuracy']), \" at epoch\", np.argmax(H.history['accuracy']) + 1)\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, balanced_accuracy_score, f1_score\n",
    "        predictions = model.predict(x=test_Data)\n",
    "        threshold = 0.5\n",
    "        wacc =  balanced_accuracy_score(test_Labels,predictions>=threshold)\n",
    "        f1 =  f1_score(test_Labels,predictions>=threshold)\n",
    "        \n",
    "        acc =  accuracy_score(test_Labels,predictions>=threshold)\n",
    "        recall = recall_score(test_Labels,predictions>=threshold)\n",
    "        auc = roc_auc_score(test_Labels,predictions>=threshold)\n",
    "        print(\"Test Accuracy:\", acc)\n",
    "        print(\"Recall Accuracy:\", recall)\n",
    "        print(\"AUC Score:\", auc)\n",
    "\n",
    "        perf[\"model\"].append(\"ActiModel\")\n",
    "        perf[\"win(sec)\"].append(winmin*60)\n",
    "        perf[\"acc\"].append(acc)\n",
    "        perf[\"recall\"].append(recall)\n",
    "        perf[\"auc\"].append(auc)\n",
    "        model_ls.append(model)\n",
    "        hist_ls.append(H)\n",
    "    perf_df = pd.DataFrame(perf)\n",
    "    print(perf_df)\n",
    "    return perf_df, model_ls, hist_ls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"lawler\"\n",
    "# group_model_W  = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "# group_model_S  = tf.keras.models.load_model('../models/ActiModels/CAD_M_F_1.000000Min.h5')\n",
    "# individual_model = tf.keras.models.load_model('../models/'+ name+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "# individual_model.trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual_model.get_weights()\n",
    "# individual_model.layers.pop(0)\n",
    "# individual_model.layers.pop(-1)\n",
    "# individual_model.layers\n",
    "# # config = individual_model._layers[-1].get_config()\n",
    "# # config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # config = individual_model._layers[-1].get_config()\n",
    "# # new_layer = Dense.from_config(config)\n",
    "# new_layer= Dense(1,activation=\"sigmoid\")\n",
    "# individual_model._layers[-1] =new_layer\n",
    "# individual_model.summary()\n",
    "# individual_model.compile(loss='binary_crossentropy',\n",
    "#                 optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# individual_model.layers.pop(-1)\n",
    "# individual_model._layers.pop(-1)\n",
    "# model.add(individual_model)\n",
    "# model.add(Dense(1, activation=\"sigmoid\",name=\"dense_7\"))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name ='lawler'\n",
    "# winmin = 1\n",
    "# win_size = 15*winmin*60\n",
    "# # in_layer = Input(shape = (win_size,6), name=\"input_4\")\n",
    "# # individual_model.layers.pop(0)\n",
    "# individual_model.layers.pop(-1)\n",
    "# # individual_model._layers.pop(0)\n",
    "# individual_model._layers.pop(-1)\n",
    "# out = individual_model(in_layer)\n",
    "# out = Dense(1, activation=\"sigmoid\",name=\"dense_7\")(out)\n",
    "# model = Model(individual_model.input , out)\n",
    "# model.summary()\n",
    "# name = \"lawler\"\n",
    "# individual_model = tf.keras.models.load_model('../models/'+ name+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "# individual_model.trainable =True\n",
    "# new_model = individual_model\n",
    "# for layer in [new_model.layers[-1]]:\n",
    "#     if hasattr(layer,'init'):\n",
    "#         input_dim = layer.input_shape[1]\n",
    "#         new_weights = layer.init((input_dim, layer.output_dim),name='{}_W'.format(layer.name))\n",
    "#         layer.trainable_weights[0].set_value(new_weights.get_value())\n",
    "        \n",
    "# new_model.compile(loss='binary_crossentropy',\n",
    "#                 optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "# perf_df_1, model_ls_1, hist_ls_1 = train_models(new_model,win_ls = [winmin],EPOCHS = 30,stridesec = 5,model_name=\"resnet_1min_transferCAD\",name = 'lawler',split_day=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 01/08/2021, 18:56:49\n",
      "WindowLength: 6.00 min (5400 datum)\tSlide: 5 (75 datum)\tEpochs:30\n",
      "\n",
      "Model to Save:  ../models/lawler_models/acti_6min_M_F_6.000000Min.h5\n",
      "\n",
      "Train:\n",
      "IndividualData/lawler-data/10.8/10.8.shm\n",
      "IndividualData/lawler-data/11.15/11.15.shm\n",
      "IndividualData/lawler-data/10.14/10.14.shm\n",
      "IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "IndividualData/lawler-data/10.12/10.12.shm\n",
      "IndividualData/lawler-data/11.11/11.11.shm\n",
      "IndividualData/lawler-data/11.4/11.4.shm\n",
      "IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "IndividualData/lawler-data/10.6/10.6.shm\n",
      "IndividualData/lawler-data/10.4/10.4.shm\n",
      "IndividualData/lawler-data/10.28/10.28.shm\n",
      "IndividualData/lawler-data/11.3/11.3.shm\n",
      "IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "IndividualData/lawler-data/10.26/10.26.shm\n",
      "IndividualData/lawler-data/10.31/10.31.shm\n",
      "IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "IndividualData/lawler-data/10.21/10.21.shm\n",
      "IndividualData/lawler-data/10.16/10.16.shm\n",
      "IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "\n",
      "test: \n",
      "IndividualData/lawler-data/10.19/10.19.shm\n",
      "IndividualData/lawler-data/11.14/11.14.shm\n",
      "IndividualData/lawler-data/10.10/10.10.shm\n",
      "IndividualData/lawler-data/11.2/11.2.shm\n",
      "\n",
      "All files: \n",
      "IndividualData/lawler-data/10.19/10.19.shm\n",
      "IndividualData/lawler-data/11.14/11.14.shm\n",
      "IndividualData/lawler-data/10.10/10.10.shm\n",
      "IndividualData/lawler-data/11.2/11.2.shm\n",
      "IndividualData/lawler-data/10.8/10.8.shm\n",
      "IndividualData/lawler-data/11.15/11.15.shm\n",
      "IndividualData/lawler-data/10.14/10.14.shm\n",
      "IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "IndividualData/lawler-data/10.12/10.12.shm\n",
      "IndividualData/lawler-data/11.11/11.11.shm\n",
      "IndividualData/lawler-data/11.4/11.4.shm\n",
      "IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "IndividualData/lawler-data/10.6/10.6.shm\n",
      "IndividualData/lawler-data/10.4/10.4.shm\n",
      "IndividualData/lawler-data/10.28/10.28.shm\n",
      "IndividualData/lawler-data/11.3/11.3.shm\n",
      "IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "IndividualData/lawler-data/10.26/10.26.shm\n",
      "IndividualData/lawler-data/10.31/10.31.shm\n",
      "IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "IndividualData/lawler-data/10.21/10.21.shm\n",
      "IndividualData/lawler-data/10.16/10.16.shm\n",
      "IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.8/10.8.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.15/11.15.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.14/10.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.12/10.12.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.11/11.11.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.4/11.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.6/10.6.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.4/10.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.28/10.28.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.3/11.3.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.26/10.26.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.21/10.21.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.16/10.16.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.14/11.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.10/10.10.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.2/11.2.shm\n",
      "Train set size: 73436, with 3590 positive samples and 69846 negative samples\n",
      "Test set size: 18359, with 898 positive samples and 17461 negative samples\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 21s 371ms/step - loss: 1.8634 - accuracy: 0.5928 - val_loss: 1.3382 - val_accuracy: 0.6097\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 1.0726 - accuracy: 0.6682 - val_loss: 0.6734 - val_accuracy: 0.8725\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.7862 - accuracy: 0.7315 - val_loss: 0.6340 - val_accuracy: 0.7798\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 20s 354ms/step - loss: 0.6909 - accuracy: 0.7462 - val_loss: 0.5347 - val_accuracy: 0.8116\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 20s 352ms/step - loss: 0.6344 - accuracy: 0.7546 - val_loss: 0.8634 - val_accuracy: 0.5267\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 20s 354ms/step - loss: 0.6085 - accuracy: 0.7609 - val_loss: 0.4939 - val_accuracy: 0.7962\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 20s 359ms/step - loss: 0.5898 - accuracy: 0.7695 - val_loss: 0.4204 - val_accuracy: 0.8474\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 20s 351ms/step - loss: 0.5790 - accuracy: 0.7662 - val_loss: 0.6487 - val_accuracy: 0.6588\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 20s 352ms/step - loss: 0.5525 - accuracy: 0.7880 - val_loss: 0.4434 - val_accuracy: 0.8126\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5501 - accuracy: 0.7808 - val_loss: 0.4874 - val_accuracy: 0.7765\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 20s 355ms/step - loss: 0.5306 - accuracy: 0.8000 - val_loss: 0.5305 - val_accuracy: 0.7446\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5279 - accuracy: 0.8031 - val_loss: 0.5117 - val_accuracy: 0.7598\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 20s 352ms/step - loss: 0.5250 - accuracy: 0.8075 - val_loss: 0.5286 - val_accuracy: 0.7484\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 20s 357ms/step - loss: 0.5235 - accuracy: 0.8050 - val_loss: 0.5337 - val_accuracy: 0.7433\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 20s 356ms/step - loss: 0.5232 - accuracy: 0.8061 - val_loss: 0.5429 - val_accuracy: 0.7365\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5231 - accuracy: 0.8061 - val_loss: 0.5350 - val_accuracy: 0.7426\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 20s 352ms/step - loss: 0.5229 - accuracy: 0.8058 - val_loss: 0.5357 - val_accuracy: 0.7421\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 20s 351ms/step - loss: 0.5228 - accuracy: 0.8061 - val_loss: 0.5370 - val_accuracy: 0.7409\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 21s 361ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5373 - val_accuracy: 0.7403\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 20s 351ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5374 - val_accuracy: 0.7402\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5374 - val_accuracy: 0.7402\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5375 - val_accuracy: 0.7402\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 20s 354ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5375 - val_accuracy: 0.7402\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5375 - val_accuracy: 0.7402\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5376 - val_accuracy: 0.7402\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 0.5228 - accuracy: 0.8063 - val_loss: 0.5376 - val_accuracy: 0.7402\n",
      "Epoch 27/30\n",
      "34/57 [================>.............] - ETA: 5s - loss: 0.5247 - accuracy: 0.8084"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-bf75ab823fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m model_1.compile(loss='binary_crossentropy',\n\u001b[1;32m      5\u001b[0m                 optimizer='adam', metrics=['accuracy'])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mperf_df_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ls_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_ls_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwin_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwinmin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstridesec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"acti_6min\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lawler\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_day\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-72b43c46a550>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(model, win_ls, EPOCHS, stridesec, name, model_name, random_seed, split_day, test_balanced)\u001b[0m\n\u001b[1;32m    115\u001b[0m                                              mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.)\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         H = model.fit(x=balancedData, y = balancedLabels,\n\u001b[0m\u001b[1;32m    118\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_balancedData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_balancedLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mlenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "winmin= 6\n",
    "win_size = 15*winmin*60\n",
    "model_1 = acti_model(input_shape =(win_size,6) )\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "perf_df_1, model_ls_1, hist_ls_1 = train_models(model_1,win_ls = [winmin],EPOCHS = 30,stridesec = 5,model_name=\"acti_6min\",name = \"lawler\",split_day=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 01/07/2021, 11:53:59\n",
      "WindowLength: 1.00 min (900 datum)\tSlide: 5 (75 datum)\tEpochs:30\n",
      "\n",
      "Model to Save:  ../models/wenkanw_models/resnet_M_F_1.000000Min.h5\n",
      "\n",
      "Train:\n",
      "IndividualData/wenkanw-data/11-21-20/Dinner/Dinner.shm\n",
      "IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n",
      "IndividualData/wenkanw-data/9-29-20/9-29-20.shm\n",
      "IndividualData/wenkanw-data/11-22-20/Lunch/Lunch.shm\n",
      "IndividualData/wenkanw-data/11-21-20/lunch/lunch.shm\n",
      "IndividualData/wenkanw-data/10-9-20/10-9-20.shm\n",
      "IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "IndividualData/wenkanw-data/10-12-20/10-12-20.shm\n",
      "IndividualData/wenkanw-data/11-16-20/11-16-20.shm\n",
      "IndividualData/wenkanw-data/9-27-20/9-27-20.shm\n",
      "IndividualData/wenkanw-data/10-3-20/10-3-20.shm\n",
      "IndividualData/wenkanw-data/10-10-20/10-10-20.shm\n",
      "IndividualData/wenkanw-data/11-22-20/Dinner/Dinner.shm\n",
      "\n",
      "test: \n",
      "IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "\n",
      "All files: \n",
      "IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "IndividualData/wenkanw-data/11-21-20/Dinner/Dinner.shm\n",
      "IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n",
      "IndividualData/wenkanw-data/9-29-20/9-29-20.shm\n",
      "IndividualData/wenkanw-data/11-22-20/Lunch/Lunch.shm\n",
      "IndividualData/wenkanw-data/11-21-20/lunch/lunch.shm\n",
      "IndividualData/wenkanw-data/10-9-20/10-9-20.shm\n",
      "IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "IndividualData/wenkanw-data/10-12-20/10-12-20.shm\n",
      "IndividualData/wenkanw-data/11-16-20/11-16-20.shm\n",
      "IndividualData/wenkanw-data/9-27-20/9-27-20.shm\n",
      "IndividualData/wenkanw-data/10-3-20/10-3-20.shm\n",
      "IndividualData/wenkanw-data/10-10-20/10-10-20.shm\n",
      "IndividualData/wenkanw-data/11-22-20/Dinner/Dinner.shm\n",
      "\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-21-20/Dinner/Dinner.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-29-20/9-29-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-22-20/Lunch/Lunch.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-21-20/lunch/lunch.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-9-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-12-20/10-12-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-16-20/11-16-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-27-20/9-27-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-3-20/10-3-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-10-20/10-10-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-22-20/Dinner/Dinner.shm\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "Train set size: 56025, with 3395 positive samples and 52630 negative samples\n",
      "Test set size: 14007, with 849 positive samples and 13158 negative samples\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 6s 110ms/step - loss: 2.4952 - accuracy: 0.7135 - val_loss: 1.8222 - val_accuracy: 0.8925\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 1.4718 - accuracy: 0.8345 - val_loss: 1.1976 - val_accuracy: 0.8417\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.9555 - accuracy: 0.8368 - val_loss: 0.7135 - val_accuracy: 0.9482\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.7554 - accuracy: 0.8451 - val_loss: 0.7112 - val_accuracy: 0.9037\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.6684 - accuracy: 0.8533 - val_loss: 0.6419 - val_accuracy: 0.9083\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.6119 - accuracy: 0.8610 - val_loss: 0.5421 - val_accuracy: 0.9344\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.5583 - accuracy: 0.8655 - val_loss: 0.5172 - val_accuracy: 0.9342\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.5274 - accuracy: 0.8672 - val_loss: 0.4699 - val_accuracy: 0.9401\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.4943 - accuracy: 0.8738 - val_loss: 0.5054 - val_accuracy: 0.9150\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.4650 - accuracy: 0.8810 - val_loss: 0.5352 - val_accuracy: 0.8854\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.4695 - accuracy: 0.8714 - val_loss: 0.3977 - val_accuracy: 0.9427\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.4354 - accuracy: 0.8848 - val_loss: 0.3793 - val_accuracy: 0.9418\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.4233 - accuracy: 0.8845 - val_loss: 0.5261 - val_accuracy: 0.8691\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.4063 - accuracy: 0.8890 - val_loss: 0.3833 - val_accuracy: 0.9318\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.4094 - accuracy: 0.8866 - val_loss: 0.3325 - val_accuracy: 0.9530\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3903 - accuracy: 0.8903 - val_loss: 0.2800 - val_accuracy: 0.9642\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.3902 - accuracy: 0.8873 - val_loss: 0.3893 - val_accuracy: 0.9204\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3665 - accuracy: 0.8975 - val_loss: 0.3841 - val_accuracy: 0.9240\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3525 - accuracy: 0.9035 - val_loss: 0.4236 - val_accuracy: 0.9063\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3375 - accuracy: 0.9077 - val_loss: 0.3462 - val_accuracy: 0.9357\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3298 - accuracy: 0.9138 - val_loss: 0.3082 - val_accuracy: 0.9506\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3285 - accuracy: 0.9128 - val_loss: 0.3117 - val_accuracy: 0.9472\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.3248 - accuracy: 0.9140 - val_loss: 0.3399 - val_accuracy: 0.9365\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.3242 - accuracy: 0.9155 - val_loss: 0.3454 - val_accuracy: 0.9335\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3239 - accuracy: 0.9161 - val_loss: 0.3406 - val_accuracy: 0.9357\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3233 - accuracy: 0.9147 - val_loss: 0.3417 - val_accuracy: 0.9350\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3232 - accuracy: 0.9158 - val_loss: 0.3410 - val_accuracy: 0.9350\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3227 - accuracy: 0.9152 - val_loss: 0.3411 - val_accuracy: 0.9351\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3245 - accuracy: 0.9161 - val_loss: 0.3407 - val_accuracy: 0.9354\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.3225 - accuracy: 0.9175 - val_loss: 0.3418 - val_accuracy: 0.9347\n",
      "Max value:  0.9175257682800293  at epoch 30\n",
      "Test Accuracy: 0.8049344641480339\n",
      "Recall Accuracy: 0.6684656900539707\n",
      "AUC Score: 0.8049344641480339\n",
      "       model  win(sec)       acc    recall       auc\n",
      "0  ActiModel        60  0.804934  0.668466  0.804934\n"
     ]
    }
   ],
   "source": [
    "winmin= 1\n",
    "win_size = 15*winmin*60\n",
    "model_1 = res_model(input_shape =(900,6) )\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "perf_df_1, model_ls_1, hist_ls_1 = train_models(model_1,win_ls = [1],EPOCHS = 30,stridesec = 5,model_name=\"resnet\",name = \"wenkanw\",split_day=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 01/07/2021, 11:57:14\n",
      "WindowLength: 1.00 min (900 datum)\tSlide: 5 (75 datum)\tEpochs:30\n",
      "\n",
      "Model to Save:  ../models/adam_models/resnet_M_F_1.000000Min.h5\n",
      "\n",
      "Train:\n",
      "IndividualData/adam-data/12-02-2020/12-02-2020.shm\n",
      "IndividualData/adam-data/12-10-2020/12-10-2020.shm\n",
      "IndividualData/adam-data/09-22-2020/09-22-2020.shm\n",
      "IndividualData/adam-data/11-25-2020/11-25-2020.shm\n",
      "IndividualData/adam-data/11-12-2020/11-12-2020.shm\n",
      "IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "IndividualData/adam-data/11-17-2020/11-17-2020.shm\n",
      "IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "IndividualData/adam-data/12-07-2020/12-07-2020.shm\n",
      "IndividualData/adam-data/12-04-2020/12-04-2020.shm\n",
      "IndividualData/adam-data/12-03-2020/12-03-2020.shm\n",
      "IndividualData/adam-data/11-11-2020/11-11-2020-1.shm\n",
      "IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "IndividualData/adam-data/11-16-2020/11-16-2020.shm\n",
      "IndividualData/adam-data/11-09-2020/11-09-2020.shm\n",
      "IndividualData/adam-data/12-01-2020/12-01-2020.shm\n",
      "\n",
      "test: \n",
      "IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "\n",
      "All files: \n",
      "IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "IndividualData/adam-data/12-02-2020/12-02-2020.shm\n",
      "IndividualData/adam-data/12-10-2020/12-10-2020.shm\n",
      "IndividualData/adam-data/09-22-2020/09-22-2020.shm\n",
      "IndividualData/adam-data/11-25-2020/11-25-2020.shm\n",
      "IndividualData/adam-data/11-12-2020/11-12-2020.shm\n",
      "IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "IndividualData/adam-data/11-17-2020/11-17-2020.shm\n",
      "IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "IndividualData/adam-data/12-07-2020/12-07-2020.shm\n",
      "IndividualData/adam-data/12-04-2020/12-04-2020.shm\n",
      "IndividualData/adam-data/12-03-2020/12-03-2020.shm\n",
      "IndividualData/adam-data/11-11-2020/11-11-2020-1.shm\n",
      "IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "IndividualData/adam-data/11-16-2020/11-16-2020.shm\n",
      "IndividualData/adam-data/11-09-2020/11-09-2020.shm\n",
      "IndividualData/adam-data/12-01-2020/12-01-2020.shm\n",
      "\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-02-2020/12-02-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-10-2020/12-10-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/09-22-2020/09-22-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-25-2020/11-25-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-12-2020/11-12-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-17-2020/11-17-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-07-2020/12-07-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-04-2020/12-04-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-03-2020/12-03-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-11-2020/11-11-2020-1.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-16-2020/11-16-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-09-2020/11-09-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-01-2020/12-01-2020.shm\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Train set size: 74230, with 2002 positive samples and 72228 negative samples\n",
      "Test set size: 18558, with 500 positive samples and 18058 negative samples\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 5s 147ms/step - loss: 2.7337 - accuracy: 0.7083 - val_loss: 2.3109 - val_accuracy: 0.7574\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 2.0131 - accuracy: 0.7852 - val_loss: 1.7457 - val_accuracy: 0.7251\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 1.4380 - accuracy: 0.8387 - val_loss: 1.3619 - val_accuracy: 0.7207\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 1.0590 - accuracy: 0.8616 - val_loss: 1.0406 - val_accuracy: 0.7835\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.8291 - accuracy: 0.8719 - val_loss: 0.9134 - val_accuracy: 0.7436\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.7237 - accuracy: 0.8804 - val_loss: 0.8008 - val_accuracy: 0.7942\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.6408 - accuracy: 0.8951 - val_loss: 0.7182 - val_accuracy: 0.8185\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 0.5945 - accuracy: 0.9013 - val_loss: 0.6499 - val_accuracy: 0.8425\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 5s 143ms/step - loss: 0.5515 - accuracy: 0.9138 - val_loss: 0.6241 - val_accuracy: 0.8371\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.5224 - accuracy: 0.9121 - val_loss: 0.5576 - val_accuracy: 0.8755\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.4937 - accuracy: 0.9196 - val_loss: 0.5153 - val_accuracy: 0.8850\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.4892 - accuracy: 0.9113 - val_loss: 0.6011 - val_accuracy: 0.8167\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.4575 - accuracy: 0.9201 - val_loss: 0.5196 - val_accuracy: 0.8677\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.4294 - accuracy: 0.9318 - val_loss: 0.4439 - val_accuracy: 0.9120\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.4221 - accuracy: 0.9293 - val_loss: 0.5220 - val_accuracy: 0.8543\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.4081 - accuracy: 0.9286 - val_loss: 0.4283 - val_accuracy: 0.9020\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3949 - accuracy: 0.9318 - val_loss: 0.4273 - val_accuracy: 0.9020\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3878 - accuracy: 0.9321 - val_loss: 0.3998 - val_accuracy: 0.9113\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.3639 - accuracy: 0.9373 - val_loss: 0.3362 - val_accuracy: 0.9424\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.3681 - accuracy: 0.9318 - val_loss: 0.4071 - val_accuracy: 0.9046\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.3556 - accuracy: 0.9383 - val_loss: 0.3495 - val_accuracy: 0.9281\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.3369 - accuracy: 0.9461 - val_loss: 0.3842 - val_accuracy: 0.9048\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.3212 - accuracy: 0.9553 - val_loss: 0.3899 - val_accuracy: 0.9026\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3137 - accuracy: 0.9570 - val_loss: 0.3606 - val_accuracy: 0.9177\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3120 - accuracy: 0.9568 - val_loss: 0.3693 - val_accuracy: 0.9149\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.3078 - accuracy: 0.9585 - val_loss: 0.3547 - val_accuracy: 0.9213\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.3083 - accuracy: 0.9603 - val_loss: 0.3521 - val_accuracy: 0.9224\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.3081 - accuracy: 0.9610 - val_loss: 0.3537 - val_accuracy: 0.9218\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.3072 - accuracy: 0.9588 - val_loss: 0.3523 - val_accuracy: 0.9225\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3076 - accuracy: 0.9590 - val_loss: 0.3517 - val_accuracy: 0.9227\n",
      "Max value:  0.9610389471054077  at epoch 28\n",
      "Test Accuracy: 0.9210526315789473\n",
      "Recall Accuracy: 0.8648325358851675\n",
      "AUC Score: 0.9210526315789475\n",
      "       model  win(sec)       acc    recall       auc\n",
      "0  ActiModel        60  0.921053  0.864833  0.921053\n"
     ]
    }
   ],
   "source": [
    "winmin= 1\n",
    "win_size = 15*winmin*60\n",
    "model_1 = res_model(input_shape =(900,6) )\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "perf_df_2, model_ls_2, hist_ls_2 = train_models(model_1,win_ls = [1],EPOCHS = 30,stridesec = 5,model_name=\"resnet\",name = \"adam\",split_day=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 01/07/2021, 11:59:55\n",
      "WindowLength: 1.00 min (900 datum)\tSlide: 5 (75 datum)\tEpochs:30\n",
      "\n",
      "Model to Save:  ../models/lawler_models/resnet_M_F_1.000000Min.h5\n",
      "\n",
      "Train:\n",
      "IndividualData/lawler-data/10.8/10.8.shm\n",
      "IndividualData/lawler-data/11.15/11.15.shm\n",
      "IndividualData/lawler-data/10.14/10.14.shm\n",
      "IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "IndividualData/lawler-data/10.12/10.12.shm\n",
      "IndividualData/lawler-data/11.11/11.11.shm\n",
      "IndividualData/lawler-data/11.4/11.4.shm\n",
      "IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "IndividualData/lawler-data/10.6/10.6.shm\n",
      "IndividualData/lawler-data/10.4/10.4.shm\n",
      "IndividualData/lawler-data/10.28/10.28.shm\n",
      "IndividualData/lawler-data/11.3/11.3.shm\n",
      "IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "IndividualData/lawler-data/10.26/10.26.shm\n",
      "IndividualData/lawler-data/10.31/10.31.shm\n",
      "IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "IndividualData/lawler-data/10.21/10.21.shm\n",
      "IndividualData/lawler-data/10.16/10.16.shm\n",
      "IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "\n",
      "test: \n",
      "IndividualData/lawler-data/10.19/10.19.shm\n",
      "IndividualData/lawler-data/11.14/11.14.shm\n",
      "IndividualData/lawler-data/10.10/10.10.shm\n",
      "IndividualData/lawler-data/11.2/11.2.shm\n",
      "\n",
      "All files: \n",
      "IndividualData/lawler-data/10.19/10.19.shm\n",
      "IndividualData/lawler-data/11.14/11.14.shm\n",
      "IndividualData/lawler-data/10.10/10.10.shm\n",
      "IndividualData/lawler-data/11.2/11.2.shm\n",
      "IndividualData/lawler-data/10.8/10.8.shm\n",
      "IndividualData/lawler-data/11.15/11.15.shm\n",
      "IndividualData/lawler-data/10.14/10.14.shm\n",
      "IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "IndividualData/lawler-data/10.12/10.12.shm\n",
      "IndividualData/lawler-data/11.11/11.11.shm\n",
      "IndividualData/lawler-data/11.4/11.4.shm\n",
      "IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "IndividualData/lawler-data/10.6/10.6.shm\n",
      "IndividualData/lawler-data/10.4/10.4.shm\n",
      "IndividualData/lawler-data/10.28/10.28.shm\n",
      "IndividualData/lawler-data/11.3/11.3.shm\n",
      "IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "IndividualData/lawler-data/10.26/10.26.shm\n",
      "IndividualData/lawler-data/10.31/10.31.shm\n",
      "IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "IndividualData/lawler-data/10.21/10.21.shm\n",
      "IndividualData/lawler-data/10.16/10.16.shm\n",
      "IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.8/10.8.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.15/11.15.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.14/10.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.12/10.12.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.11/11.11.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.4/11.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.6/10.6.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.4/10.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.28/10.28.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.3/11.3.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.26/10.26.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.21/10.21.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.16/10.16.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.14/11.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.10/10.10.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.2/11.2.shm\n",
      "Train set size: 74348, with 3732 positive samples and 70616 negative samples\n",
      "Test set size: 18587, with 933 positive samples and 17654 negative samples\n",
      "Epoch 1/30\n",
      "59/59 [==============================] - 7s 115ms/step - loss: 2.4810 - accuracy: 0.5977 - val_loss: 1.9443 - val_accuracy: 0.4569\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 1.4767 - accuracy: 0.6594 - val_loss: 1.1242 - val_accuracy: 0.6613\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.9768 - accuracy: 0.6756 - val_loss: 0.8182 - val_accuracy: 0.7149\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.8112 - accuracy: 0.6913 - val_loss: 0.8266 - val_accuracy: 0.5717\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.7310 - accuracy: 0.7053 - val_loss: 0.6676 - val_accuracy: 0.7923\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.6790 - accuracy: 0.7249 - val_loss: 0.7478 - val_accuracy: 0.5955\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.6354 - accuracy: 0.7375 - val_loss: 0.5209 - val_accuracy: 0.8848\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.6102 - accuracy: 0.7552 - val_loss: 0.6531 - val_accuracy: 0.7097\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.6111 - accuracy: 0.7485 - val_loss: 0.6323 - val_accuracy: 0.7136\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.5832 - accuracy: 0.7649 - val_loss: 0.5521 - val_accuracy: 0.8041\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.5515 - accuracy: 0.7851 - val_loss: 0.5885 - val_accuracy: 0.7598\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.5477 - accuracy: 0.7870 - val_loss: 0.5894 - val_accuracy: 0.7560\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.5431 - accuracy: 0.7922 - val_loss: 0.5553 - val_accuracy: 0.7887\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.5390 - accuracy: 0.7930 - val_loss: 0.5505 - val_accuracy: 0.7909\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.5386 - accuracy: 0.7950 - val_loss: 0.5627 - val_accuracy: 0.7790\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5386 - accuracy: 0.7949 - val_loss: 0.5454 - val_accuracy: 0.7930\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.5380 - accuracy: 0.7964 - val_loss: 0.5491 - val_accuracy: 0.7895\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.5375 - accuracy: 0.7974 - val_loss: 0.5491 - val_accuracy: 0.7895\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5379 - accuracy: 0.7945 - val_loss: 0.5508 - val_accuracy: 0.7881\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5380 - accuracy: 0.7938 - val_loss: 0.5509 - val_accuracy: 0.7881\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 7s 112ms/step - loss: 0.5377 - accuracy: 0.7933 - val_loss: 0.5507 - val_accuracy: 0.7881\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5375 - accuracy: 0.7969 - val_loss: 0.5509 - val_accuracy: 0.7879\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.5379 - accuracy: 0.7954 - val_loss: 0.5506 - val_accuracy: 0.7883\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5375 - accuracy: 0.7947 - val_loss: 0.5506 - val_accuracy: 0.7882\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 0.5375 - accuracy: 0.7938 - val_loss: 0.5506 - val_accuracy: 0.7885\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.5383 - accuracy: 0.7926 - val_loss: 0.5506 - val_accuracy: 0.7883\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 7s 110ms/step - loss: 0.5374 - accuracy: 0.7945 - val_loss: 0.5508 - val_accuracy: 0.7881\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 7s 110ms/step - loss: 0.5374 - accuracy: 0.7962 - val_loss: 0.5507 - val_accuracy: 0.7880\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 7s 110ms/step - loss: 0.5376 - accuracy: 0.7954 - val_loss: 0.5508 - val_accuracy: 0.7883\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.5374 - accuracy: 0.7938 - val_loss: 0.5508 - val_accuracy: 0.7881\n",
      "Max value:  0.7974276542663574  at epoch 18\n",
      "Test Accuracy: 0.772215269086358\n",
      "Recall Accuracy: 0.72090112640801\n",
      "AUC Score: 0.7722152690863578\n",
      "       model  win(sec)       acc    recall       auc\n",
      "0  ActiModel        60  0.772215  0.720901  0.772215\n"
     ]
    }
   ],
   "source": [
    "winmin= 1\n",
    "win_size = 15*winmin*60\n",
    "model_1 = res_model(input_shape =(900,6) )\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "perf_df_3, model_ls_3, hist_ls_3 = train_models(model_1,win_ls = [1],EPOCHS = 30,stridesec = 5,model_name=\"resnet\",name = \"lawler\",split_day=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 01/07/2021, 13:43:55\n",
      "WindowLength: 1.00 min (900 datum)\tSlide: 5 (75 datum)\tEpochs:30\n",
      "\n",
      "Model to Save:  ../models/shaurya_models/resnet_M_F_1.000000Min.h5\n",
      "\n",
      "Train:\n",
      "IndividualData/shaurya-data/10.22.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.15.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.17.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.1.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.18.2020/Data.shm\n",
      "\n",
      "test: \n",
      "IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "\n",
      "All files: \n",
      "IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "IndividualData/shaurya-data/10.22.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.15.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.17.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.1.2020/Data.shm\n",
      "IndividualData/shaurya-data/11.18.2020/Data.shm\n",
      "\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.22.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.15.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.17.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.1.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.18.2020/Data.shm\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "Train set size: 32164, with 2025 positive samples and 30139 negative samples\n",
      "Test set size: 8041, with 506 positive samples and 7535 negative samples\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 2.7826 - accuracy: 0.6514 - val_loss: 2.5646 - val_accuracy: 0.4792\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 2.0731 - accuracy: 0.7422 - val_loss: 1.8137 - val_accuracy: 0.7294\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 1.5234 - accuracy: 0.7523 - val_loss: 1.2658 - val_accuracy: 0.8268\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 1.1291 - accuracy: 0.7706 - val_loss: 0.9237 - val_accuracy: 0.8807\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.8828 - accuracy: 0.7817 - val_loss: 0.7851 - val_accuracy: 0.8622\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.7526 - accuracy: 0.7975 - val_loss: 0.7124 - val_accuracy: 0.8628\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.6846 - accuracy: 0.8143 - val_loss: 0.6581 - val_accuracy: 0.8676\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.6546 - accuracy: 0.8148 - val_loss: 0.6577 - val_accuracy: 0.8465\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.6155 - accuracy: 0.8326 - val_loss: 0.5459 - val_accuracy: 0.9117\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.5880 - accuracy: 0.8333 - val_loss: 0.5116 - val_accuracy: 0.9041\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.5565 - accuracy: 0.8457 - val_loss: 0.5165 - val_accuracy: 0.8884\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.5238 - accuracy: 0.8622 - val_loss: 0.5577 - val_accuracy: 0.8457\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.4978 - accuracy: 0.8711 - val_loss: 0.5498 - val_accuracy: 0.8584\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4711 - accuracy: 0.8852 - val_loss: 0.4722 - val_accuracy: 0.8916\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4579 - accuracy: 0.8923 - val_loss: 0.4736 - val_accuracy: 0.8927\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4534 - accuracy: 0.8923 - val_loss: 0.4520 - val_accuracy: 0.9035\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4515 - accuracy: 0.8948 - val_loss: 0.4442 - val_accuracy: 0.9023\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4502 - accuracy: 0.8946 - val_loss: 0.4429 - val_accuracy: 0.8986\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4457 - accuracy: 0.8953 - val_loss: 0.4820 - val_accuracy: 0.8794\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4454 - accuracy: 0.8938 - val_loss: 0.4300 - val_accuracy: 0.9041\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4413 - accuracy: 0.8956 - val_loss: 0.5135 - val_accuracy: 0.8631\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.4387 - accuracy: 0.9015 - val_loss: 0.4958 - val_accuracy: 0.8719\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.4377 - accuracy: 0.9007 - val_loss: 0.4726 - val_accuracy: 0.8805\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.4345 - accuracy: 0.9005 - val_loss: 0.4677 - val_accuracy: 0.8817\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4340 - accuracy: 0.9007 - val_loss: 0.4683 - val_accuracy: 0.8821\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.4332 - accuracy: 0.9054 - val_loss: 0.4649 - val_accuracy: 0.8836\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.4322 - accuracy: 0.9017 - val_loss: 0.4677 - val_accuracy: 0.8819\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4324 - accuracy: 0.9002 - val_loss: 0.4686 - val_accuracy: 0.8817\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4309 - accuracy: 0.9015 - val_loss: 0.4691 - val_accuracy: 0.8819\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.4329 - accuracy: 0.9017 - val_loss: 0.4696 - val_accuracy: 0.8816\n",
      "Max value:  0.9054321050643921  at epoch 26\n",
      "Test Accuracy: 0.4766666666666667\n",
      "Recall Accuracy: 0.12333333333333334\n",
      "AUC Score: 0.4766666666666666\n",
      "       model  win(sec)       acc    recall       auc\n",
      "0  ActiModel        60  0.476667  0.123333  0.476667\n"
     ]
    }
   ],
   "source": [
    "winmin= 1\n",
    "win_size = 15*winmin*60\n",
    "model_1 = res_model(input_shape =(900,6) )\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "perf_df_4, model_ls_4, hist_ls_4 = train_models(model_1,win_ls = [1],EPOCHS = 30,stridesec = 5,model_name=\"resnet\",name = \"shaurya\",split_day=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test_models(winmin=1, stridesec = 5,names= [\"wenkanw\"],random_seed=1000, split_day=False):\n",
    "    perf = defaultdict(list)\n",
    "    meal_info = defaultdict(list)\n",
    "    for name in names:\n",
    "        person = name\n",
    "        if split_day:\n",
    "            meal_data = Person_MealsDataset(person_name= person, file_name = \"test_files\", winmin = winmin,stridesec = stridesec)\n",
    "\n",
    "            # balance test set\n",
    "            testset_labels = meal_data.labels\n",
    "            test_indices = balance_data_indices(testset_labels,data_indices=[i for i in range(len(meal_data))] ,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "            # get numpy dataset\n",
    "            test_Data, test_Labels = meal_data.get_subset(test_indices)\n",
    "        else:            \n",
    "            meal_data = Person_MealsDataset(person_name= person, file_name = \"all_files_list\", winmin = winmin,stridesec = stridesec)\n",
    "            samples,labels =  meal_data.data_indices, meal_data.labels\n",
    "            # split train set and test set\n",
    "            train_indices, test_indices = split_train_test_indices(X= [i for i in range(len(labels))],\n",
    "                                                                            y = labels, test_size = 0.2,\n",
    "                                                                           random_seed = random_seed)\n",
    "            testset_labels = labels[test_indices]\n",
    "            test_indices = balance_data_indices(testset_labels,data_indices= test_indices,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n",
    "            test_Data, test_Labels = meal_data.get_subset(test_indices)\n",
    "        if name !=\"CAD\":\n",
    "            meal_counts, min_counts,hour_counts, day_counts,total_hours = meal_data.get_mealdataset_info(person_name=name)\n",
    "        else:\n",
    "            # data from paper\n",
    "            meal_counts, min_counts,hour_counts, day_counts,total_hours = 1063, 250*60,250, 354, 4680\n",
    "        meal_info[\"dataset\"].append(name)\n",
    "        meal_info[\"Days\"].append(day_counts)\n",
    "        meal_info[\"Meal_Hours\"].append(round(hour_counts,1)) \n",
    "#         meal_info[\"Meal_Minutes\"].append(round(min_counts,1))\n",
    "        meal_info[\"Meal_Counts\"].append(meal_counts) \n",
    "        meal_info[\"Total_Hours\"].append(total_hours) \n",
    "        \n",
    "        perf[\"dataset\"].append(name)\n",
    "        perf[\"win(sec)\"].append(winmin*60)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score\n",
    "        group_model_W  = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "        group_model_S  = tf.keras.models.load_model('../models/ActiModels/CAD_M_F_1.000000Min.h5')\n",
    "        if name != \"CAD\":\n",
    "            if split_day:\n",
    "                individual_model = tf.keras.models.load_model('../models/'+ name+ '_models/resnet_split_day_M_F_1.000000Min.h5')\n",
    "            else:    \n",
    "                individual_model = tf.keras.models.load_model('../models/'+ name+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "        models = {\"suffix\":['Individual-Model','W-GroupModel',\"S-GroupModel\"],  \"model\":[individual_model,group_model_W,group_model_S]}\n",
    "        \n",
    "        for i in range(len(models[\"suffix\"])):\n",
    "            suffix = models[\"suffix\"][i]\n",
    "            model = models[\"model\"][i]\n",
    "            # if the dataset is CAD group dataset and model is individual model\n",
    "            # we don't need to make prediction on that data\n",
    "            if name == \"CAD\" and suffix =='Individual-Model':\n",
    "                acc = None\n",
    "                auc = None\n",
    "                recall = None\n",
    "            else:\n",
    "\n",
    "                predictions = model.predict(x=test_Data)\n",
    "                threshold = 0.5\n",
    "                acc =  accuracy_score(test_Labels,predictions>=threshold)\n",
    "                recall = recall_score(test_Labels,predictions>=threshold)\n",
    "                f1 = f1_score(test_Labels,predictions>=threshold)\n",
    "#                 auc = roc_auc_score(test_Labels,predictions>=threshold)\n",
    "\n",
    "                acc = round(acc,5)\n",
    "                recall = round(recall, 5)\n",
    "#                 auc = round(auc,5)\n",
    "                f1 = round(f1,5)\n",
    "            \n",
    "            print(\"Test Accuracy:\", acc)\n",
    "            print(\"Recall Accuracy:\", recall)\n",
    "            #print(\"AUC Score:\", auc)\n",
    "            perf[\"Acc: \"+suffix].append(acc)\n",
    "            perf[\"Recall: \"+suffix].append(recall)\n",
    "            perf[\"F1: \"+suffix].append(f1)\n",
    "            #perf[\"Auc: \"+suffix].append(auc)\n",
    "\n",
    "    meal_info = pd.DataFrame(meal_info)\n",
    "    perf_df = pd.DataFrame(perf)\n",
    "    return meal_info, perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-21-20/Dinner/Dinner.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-29-20/9-29-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-22-20/Lunch/Lunch.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-21-20/lunch/lunch.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-9-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-12-20/10-12-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-16-20/11-16-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-27-20/9-27-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-3-20/10-3-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-10-20/10-10-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-22-20/Dinner/Dinner.shm\n",
      "Train set size: 74240, with 4433 positive samples and 69807 negative samples\n",
      "Test set size: 18560, with 1108 positive samples and 17452 negative samples\n",
      "Test Accuracy: 0.9278\n",
      "Recall Accuracy: 0.93141\n",
      "Test Accuracy: 0.69449\n",
      "Recall Accuracy: 0.46029\n",
      "Test Accuracy: 0.74639\n",
      "Recall Accuracy: 0.5731\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-02-2020/12-02-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-10-2020/12-10-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/09-22-2020/09-22-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-25-2020/11-25-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-12-2020/11-12-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-17-2020/11-17-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-07-2020/12-07-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-04-2020/12-04-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-03-2020/12-03-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-11-2020/11-11-2020-1.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-16-2020/11-16-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-09-2020/11-09-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-01-2020/12-01-2020.shm\n",
      "Train set size: 97128, with 2670 positive samples and 94458 negative samples\n",
      "Test set size: 24282, with 668 positive samples and 23614 negative samples\n",
      "Test Accuracy: 0.95434\n",
      "Recall Accuracy: 0.98353\n",
      "Test Accuracy: 0.82784\n",
      "Recall Accuracy: 0.71257\n",
      "Test Accuracy: 0.79566\n",
      "Recall Accuracy: 0.68413\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.14/11.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.10/10.10.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.2/11.2.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.8/10.8.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.15/11.15.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.14/10.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.12/10.12.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.11/11.11.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.4/11.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.25/9.25_1-46.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.6/10.6.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.4/10.4.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.28/10.28.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.3/11.3.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/evening_2hr_20min/10.20.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.26/10.26.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.31/evening-2hr_goodDinnerTemplate_CFAmeal/10.31.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.21/10.21.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.16/10.16.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "Train set size: 96116, with 4371 positive samples and 91745 negative samples\n",
      "Test set size: 24029, with 1093 positive samples and 22936 negative samples\n",
      "Test Accuracy: 0.84309\n",
      "Recall Accuracy: 0.79048\n",
      "Test Accuracy: 0.65371\n",
      "Recall Accuracy: 0.52882\n",
      "Test Accuracy: 0.65416\n",
      "Recall Accuracy: 0.58188\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.22.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.15.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.17.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.1.2020/Data.shm\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.18.2020/Data.shm\n",
      "Train set size: 37752, with 2265 positive samples and 35487 negative samples\n",
      "Test set size: 9438, with 566 positive samples and 8872 negative samples\n",
      "Test Accuracy: 0.83569\n",
      "Recall Accuracy: 0.75088\n",
      "Test Accuracy: 0.66784\n",
      "Recall Accuracy: 0.36926\n",
      "Test Accuracy: 0.67933\n",
      "Recall Accuracy: 0.4311\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/ShimmerData/P2001/P2001.shm\n",
      "Loading File:  ../data/ShimmerData/P2011/P2011.shm\n",
      "Loading File:  ../data/ShimmerData/P2012/P2012.shm\n",
      "Loading File:  ../data/ShimmerData/P2013/P2013.shm\n",
      "Loading File:  ../data/ShimmerData/P2014/P2014.shm\n",
      "Loading File:  ../data/ShimmerData/P2015/P2015.shm\n",
      "Loading File:  ../data/ShimmerData/P2016/P2016.shm\n",
      "Loading File:  ../data/ShimmerData/P2017/P2017.shm\n",
      "Loading File:  ../data/ShimmerData/P2018/P2018.shm\n",
      "Loading File:  ../data/ShimmerData/P2020/P2020.shm\n",
      "Loading File:  ../data/ShimmerData/P2030/P2030.shm\n",
      "Loading File:  ../data/ShimmerData/P2031/P2031.shm\n",
      "Loading File:  ../data/ShimmerData/P2033/P2033.shm\n",
      "Loading File:  ../data/ShimmerData/P2035/P2035.shm\n",
      "Loading File:  ../data/ShimmerData/P2036/P2036.shm\n",
      "Loading File:  ../data/ShimmerData/P2037/P2037.shm\n",
      "Loading File:  ../data/ShimmerData/P2038/P2038.shm\n",
      "Loading File:  ../data/ShimmerData/P2044/P2044.shm\n",
      "Loading File:  ../data/ShimmerData/P2046/P2046.shm\n",
      "Loading File:  ../data/ShimmerData/P2051/P2051.shm\n",
      "Loading File:  ../data/ShimmerData/P2055/P2055.shm\n",
      "Loading File:  ../data/ShimmerData/P2057/P2057.shm\n",
      "Loading File:  ../data/ShimmerData/P2058/P2058.shm\n",
      "Loading File:  ../data/ShimmerData/P2063/P2063.shm\n",
      "Loading File:  ../data/ShimmerData/P2100/P2100.shm\n",
      "Loading File:  ../data/ShimmerData/P2101/P2101.shm\n",
      "Loading File:  ../data/ShimmerData/P2102/P2102.shm\n",
      "Loading File:  ../data/ShimmerData/P2103/P2103.shm\n",
      "Loading File:  ../data/ShimmerData/P2105/P2105.shm\n",
      "Loading File:  ../data/ShimmerData/P2106/P2106.shm\n",
      "Loading File:  ../data/ShimmerData/P2107/P2107.shm\n",
      "Loading File:  ../data/ShimmerData/P2108/P2108.shm\n",
      "Loading File:  ../data/ShimmerData/P2109/P2109.shm\n",
      "Loading File:  ../data/ShimmerData/P2110/P2110.shm\n",
      "Loading File:  ../data/ShimmerData/P2111/P2111.shm\n",
      "Loading File:  ../data/ShimmerData/P2113/P2113.shm\n",
      "Loading File:  ../data/ShimmerData/P2114/P2114.shm\n",
      "Loading File:  ../data/ShimmerData/P2115/P2115.shm\n",
      "Loading File:  ../data/ShimmerData/P2116/P2116.shm\n",
      "Loading File:  ../data/ShimmerData/P2117/P2117.shm\n",
      "Loading File:  ../data/ShimmerData/P2118/P2118.shm\n",
      "Loading File:  ../data/ShimmerData/P2120/P2120.shm\n",
      "Loading File:  ../data/ShimmerData/P2121/P2121.shm\n",
      "Loading File:  ../data/ShimmerData/P2122/P2122.shm\n",
      "Loading File:  ../data/ShimmerData/P2123/P2123.shm\n",
      "Loading File:  ../data/ShimmerData/P2125/P2125.shm\n",
      "Loading File:  ../data/ShimmerData/P2126/P2126.shm\n",
      "Loading File:  ../data/ShimmerData/P2127/P2127.shm\n",
      "Loading File:  ../data/ShimmerData/P2128/P2128.shm\n",
      "Loading File:  ../data/ShimmerData/P2129/P2129.shm\n",
      "Loading File:  ../data/ShimmerData/P2130/P2130.shm\n",
      "Loading File:  ../data/ShimmerData/P2131/P2131.shm\n",
      "Loading File:  ../data/ShimmerData/P2132/P2132.shm\n",
      "Loading File:  ../data/ShimmerData/P2133/P2133.shm\n",
      "Loading File:  ../data/ShimmerData/P2134/P2134.shm\n",
      "Loading File:  ../data/ShimmerData/P2135/P2135.shm\n",
      "Loading File:  ../data/ShimmerData/P2136/P2136.shm\n",
      "Loading File:  ../data/ShimmerData/P2137/P2137.shm\n",
      "Loading File:  ../data/ShimmerData/P2138/P2138.shm\n",
      "Loading File:  ../data/ShimmerData/P2139/P2139.shm\n",
      "Loading File:  ../data/ShimmerData/P2140/P2140.shm\n",
      "Loading File:  ../data/ShimmerData/P2141/P2141.shm\n",
      "Loading File:  ../data/ShimmerData/P2142/P2142.shm\n",
      "Loading File:  ../data/ShimmerData/P2143/P2143.shm\n",
      "Loading File:  ../data/ShimmerData/P2144/P2144.shm\n",
      "Loading File:  ../data/ShimmerData/P2145/P2145.shm\n",
      "Loading File:  ../data/ShimmerData/P2146/P2146.shm\n",
      "Loading File:  ../data/ShimmerData/P2147/P2147.shm\n",
      "Loading File:  ../data/ShimmerData/P2148/P2148.shm\n",
      "Loading File:  ../data/ShimmerData/P2149/P2149.shm\n",
      "Loading File:  ../data/ShimmerData/P2150/P2150.shm\n",
      "Loading File:  ../data/ShimmerData/P2151/P2151.shm\n",
      "Loading File:  ../data/ShimmerData/P2152/P2152.shm\n",
      "Loading File:  ../data/ShimmerData/P2153/P2153.shm\n",
      "Loading File:  ../data/ShimmerData/P2154/P2154.shm\n",
      "Loading File:  ../data/ShimmerData/P2155/P2155.shm\n",
      "Loading File:  ../data/ShimmerData/P2157/P2157.shm\n",
      "Loading File:  ../data/ShimmerData/P2158/P2158.shm\n",
      "Loading File:  ../data/ShimmerData/P2159/P2159.shm\n",
      "Loading File:  ../data/ShimmerData/P2160/P2160.shm\n",
      "Loading File:  ../data/ShimmerData/P2161/P2161.shm\n",
      "Loading File:  ../data/ShimmerData/P2164/P2164.shm\n",
      "Loading File:  ../data/ShimmerData/P2165/P2165.shm\n",
      "Loading File:  ../data/ShimmerData/P2166/P2166.shm\n",
      "Loading File:  ../data/ShimmerData/P2168/P2168.shm\n",
      "Loading File:  ../data/ShimmerData/P2169/P2169.shm\n",
      "Loading File:  ../data/ShimmerData/P2170/P2170.shm\n",
      "Loading File:  ../data/ShimmerData/P2171/P2171.shm\n",
      "Loading File:  ../data/ShimmerData/P2172/P2172.shm\n",
      "Loading File:  ../data/ShimmerData/P2173/P2173.shm\n",
      "Loading File:  ../data/ShimmerData/P2174/P2174.shm\n",
      "Loading File:  ../data/ShimmerData/P2175/P2175.shm\n",
      "Loading File:  ../data/ShimmerData/P2176/P2176.shm\n",
      "Loading File:  ../data/ShimmerData/P2177/P2177.shm\n",
      "Loading File:  ../data/ShimmerData/P2178/P2178.shm\n",
      "Loading File:  ../data/ShimmerData/P2179/P2179.shm\n",
      "Loading File:  ../data/ShimmerData/P2180/P2180.shm\n",
      "Loading File:  ../data/ShimmerData/P2181/P2181.shm\n",
      "Loading File:  ../data/ShimmerData/P2182/P2182.shm\n",
      "Loading File:  ../data/ShimmerData/P2183/P2183.shm\n",
      "Loading File:  ../data/ShimmerData/P2184/P2184.shm\n",
      "Loading File:  ../data/ShimmerData/P2185/P2185.shm\n",
      "Loading File:  ../data/ShimmerData/P2186/P2186.shm\n",
      "Loading File:  ../data/ShimmerData/P2187/P2187.shm\n",
      "Loading File:  ../data/ShimmerData/P2188/P2188.shm\n",
      "Loading File:  ../data/ShimmerData/P2189/P2189.shm\n",
      "Loading File:  ../data/ShimmerData/P2190/P2190.shm\n",
      "Loading File:  ../data/ShimmerData/P2191/P2191.shm\n",
      "Loading File:  ../data/ShimmerData/P2192/P2192.shm\n",
      "Loading File:  ../data/ShimmerData/P2193/P2193.shm\n",
      "Loading File:  ../data/ShimmerData/P2194/P2194.shm\n",
      "Loading File:  ../data/ShimmerData/P2195/P2195.shm\n",
      "Loading File:  ../data/ShimmerData/P2196/P2196.shm\n",
      "Loading File:  ../data/ShimmerData/P2197/P2197.shm\n",
      "Loading File:  ../data/ShimmerData/P2198/P2198.shm\n",
      "Loading File:  ../data/ShimmerData/P2200/P2200.shm\n",
      "Loading File:  ../data/ShimmerData/P2201/P2201.shm\n",
      "Loading File:  ../data/ShimmerData/P2203/P2203.shm\n",
      "Loading File:  ../data/ShimmerData/P2204/P2204.shm\n",
      "Loading File:  ../data/ShimmerData/P2205/P2205.shm\n",
      "Loading File:  ../data/ShimmerData/P2206/P2206.shm\n",
      "Loading File:  ../data/ShimmerData/P2207/P2207.shm\n",
      "Loading File:  ../data/ShimmerData/P2208/P2208.shm\n",
      "Loading File:  ../data/ShimmerData/P2209/P2209.shm\n",
      "Loading File:  ../data/ShimmerData/P2210/P2210.shm\n",
      "Loading File:  ../data/ShimmerData/P2211/P2211.shm\n",
      "Loading File:  ../data/ShimmerData/P2212/P2212.shm\n",
      "Loading File:  ../data/ShimmerData/P2213/P2213.shm\n",
      "Loading File:  ../data/ShimmerData/P2214/P2214.shm\n",
      "Loading File:  ../data/ShimmerData/P2215/P2215.shm\n",
      "Loading File:  ../data/ShimmerData/P2216/P2216.shm\n",
      "Loading File:  ../data/ShimmerData/P2217/P2217.shm\n",
      "Loading File:  ../data/ShimmerData/P2218/P2218.shm\n",
      "Loading File:  ../data/ShimmerData/P2219/P2219.shm\n",
      "Loading File:  ../data/ShimmerData/P2221/P2221.shm\n",
      "Loading File:  ../data/ShimmerData/P2222/P2222.shm\n",
      "Loading File:  ../data/ShimmerData/P2223/P2223.shm\n",
      "Loading File:  ../data/ShimmerData/P2224/P2224.shm\n",
      "Loading File:  ../data/ShimmerData/P2226/P2226.shm\n",
      "Loading File:  ../data/ShimmerData/P2227/P2227.shm\n",
      "Loading File:  ../data/ShimmerData/P2228/P2228.shm\n",
      "Loading File:  ../data/ShimmerData/P2229/P2229.shm\n",
      "Loading File:  ../data/ShimmerData/P2230/P2230.shm\n",
      "Loading File:  ../data/ShimmerData/P2231/P2231.shm\n",
      "Loading File:  ../data/ShimmerData/P2232/P2232.shm\n",
      "Loading File:  ../data/ShimmerData/P2233/P2233.shm\n",
      "Loading File:  ../data/ShimmerData/P2234/P2234.shm\n",
      "Loading File:  ../data/ShimmerData/P2235/P2235.shm\n",
      "Loading File:  ../data/ShimmerData/P2236/P2236.shm\n",
      "Loading File:  ../data/ShimmerData/P2237/P2237.shm\n",
      "Loading File:  ../data/ShimmerData/P2238/P2238.shm\n",
      "Loading File:  ../data/ShimmerData/P2239/P2239.shm\n",
      "Loading File:  ../data/ShimmerData/P2240/P2240.shm\n",
      "Loading File:  ../data/ShimmerData/P2242/P2242.shm\n",
      "Loading File:  ../data/ShimmerData/P2243/P2243.shm\n",
      "Loading File:  ../data/ShimmerData/P2244/P2244.shm\n",
      "Loading File:  ../data/ShimmerData/P2245/P2245.shm\n",
      "Loading File:  ../data/ShimmerData/P2246/P2246.shm\n",
      "Loading File:  ../data/ShimmerData/P2247/P2247.shm\n",
      "Loading File:  ../data/ShimmerData/P2248/P2248.shm\n",
      "Loading File:  ../data/ShimmerData/P2249/P2249.shm\n",
      "Loading File:  ../data/ShimmerData/P2250/P2250.shm\n",
      "Loading File:  ../data/ShimmerData/P2251/P2251.shm\n",
      "Loading File:  ../data/ShimmerData/P2253/P2253.shm\n",
      "Loading File:  ../data/ShimmerData/P2254/P2254.shm\n",
      "Loading File:  ../data/ShimmerData/P2255/P2255.shm\n",
      "Loading File:  ../data/ShimmerData/P2256/P2256.shm\n",
      "Loading File:  ../data/ShimmerData/P2257/P2257.shm\n",
      "Loading File:  ../data/ShimmerData/P2258/P2258.shm\n",
      "Loading File:  ../data/ShimmerData/P2259/P2259.shm\n",
      "Loading File:  ../data/ShimmerData/P2262/P2262.shm\n",
      "Loading File:  ../data/ShimmerData/P2263/P2263.shm\n",
      "Loading File:  ../data/ShimmerData/P2264/P2264.shm\n",
      "Loading File:  ../data/ShimmerData/P2265/P2265.shm\n",
      "Loading File:  ../data/ShimmerData/P2267/P2267.shm\n",
      "Loading File:  ../data/ShimmerData/P2268/P2268.shm\n",
      "Loading File:  ../data/ShimmerData/P2269/P2269.shm\n",
      "Loading File:  ../data/ShimmerData/P2270/P2270.shm\n",
      "Loading File:  ../data/ShimmerData/P2271/P2271.shm\n",
      "Loading File:  ../data/ShimmerData/P2272/P2272.shm\n",
      "Loading File:  ../data/ShimmerData/P2273/P2273.shm\n",
      "Loading File:  ../data/ShimmerData/P2274/P2274.shm\n",
      "Loading File:  ../data/ShimmerData/P2275/P2275.shm\n",
      "Loading File:  ../data/ShimmerData/P2276/P2276.shm\n",
      "Loading File:  ../data/ShimmerData/P2277/P2277.shm\n",
      "Loading File:  ../data/ShimmerData/P2278/P2278.shm\n",
      "Loading File:  ../data/ShimmerData/P2280/P2280.shm\n",
      "Loading File:  ../data/ShimmerData/P2282/P2282.shm\n",
      "Loading File:  ../data/ShimmerData/P2283/P2283.shm\n",
      "Loading File:  ../data/ShimmerData/P2284/P2284.shm\n",
      "Loading File:  ../data/ShimmerData/P2285/P2285.shm\n",
      "Loading File:  ../data/ShimmerData/P2286/P2286.shm\n",
      "Loading File:  ../data/ShimmerData/P2287/P2287.shm\n",
      "Loading File:  ../data/ShimmerData/P2288/P2288.shm\n",
      "Loading File:  ../data/ShimmerData/P2289/P2289.shm\n",
      "Loading File:  ../data/ShimmerData/P2290/P2290.shm\n",
      "Loading File:  ../data/ShimmerData/P2291/P2291.shm\n",
      "Loading File:  ../data/ShimmerData/P2292/P2292.shm\n",
      "Loading File:  ../data/ShimmerData/P2293/P2293.shm\n",
      "Loading File:  ../data/ShimmerData/P2294/P2294.shm\n",
      "Loading File:  ../data/ShimmerData/P2295/P2295.shm\n",
      "Loading File:  ../data/ShimmerData/P2296/P2296.shm\n",
      "Loading File:  ../data/ShimmerData/P2298/P2298.shm\n",
      "Loading File:  ../data/ShimmerData/P2299/P2299.shm\n",
      "Loading File:  ../data/ShimmerData/P2300/P2300.shm\n",
      "Loading File:  ../data/ShimmerData/P2301/P2301.shm\n",
      "Loading File:  ../data/ShimmerData/P2302/P2302.shm\n",
      "Loading File:  ../data/ShimmerData/P2303/P2303.shm\n",
      "Loading File:  ../data/ShimmerData/P2304/P2304.shm\n",
      "Loading File:  ../data/ShimmerData/P2305/P2305.shm\n",
      "Loading File:  ../data/ShimmerData/P2306/P2306.shm\n",
      "Loading File:  ../data/ShimmerData/P2307/P2307.shm\n",
      "Loading File:  ../data/ShimmerData/P2308/P2308.shm\n",
      "Loading File:  ../data/ShimmerData/P2309/P2309.shm\n",
      "Loading File:  ../data/ShimmerData/P2311/P2311.shm\n",
      "Loading File:  ../data/ShimmerData/P2312/P2312.shm\n",
      "Loading File:  ../data/ShimmerData/P2313/P2313.shm\n",
      "Loading File:  ../data/ShimmerData/P2314/P2314.shm\n",
      "Loading File:  ../data/ShimmerData/P2315/P2315.shm\n",
      "Loading File:  ../data/ShimmerData/P2316/P2316.shm\n",
      "Loading File:  ../data/ShimmerData/P2317/P2317.shm\n",
      "Loading File:  ../data/ShimmerData/P2318/P2318.shm\n",
      "Loading File:  ../data/ShimmerData/P2319/P2319.shm\n",
      "Loading File:  ../data/ShimmerData/P2320/P2320.shm\n",
      "Loading File:  ../data/ShimmerData/P2321/P2321.shm\n",
      "Loading File:  ../data/ShimmerData/P2323/P2323.shm\n",
      "Loading File:  ../data/ShimmerData/P2325/P2325.shm\n",
      "Loading File:  ../data/ShimmerData/P2326/P2326.shm\n",
      "Loading File:  ../data/ShimmerData/P2329/P2329.shm\n",
      "Loading File:  ../data/ShimmerData/P2331/P2331.shm\n",
      "Loading File:  ../data/ShimmerData/P2332/P2332.shm\n",
      "Loading File:  ../data/ShimmerData/P2334/P2334.shm\n",
      "Loading File:  ../data/ShimmerData/P2335/P2335.shm\n",
      "Loading File:  ../data/ShimmerData/P2336/P2336.shm\n",
      "Loading File:  ../data/ShimmerData/P2337/P2337.shm\n",
      "Loading File:  ../data/ShimmerData/P2338/P2338.shm\n",
      "Loading File:  ../data/ShimmerData/P2340/P2340.shm\n",
      "Loading File:  ../data/ShimmerData/P2341/P2341.shm\n",
      "Loading File:  ../data/ShimmerData/P2342/P2342.shm\n",
      "Loading File:  ../data/ShimmerData/P2343/P2343.shm\n",
      "Loading File:  ../data/ShimmerData/P2344/P2344.shm\n",
      "Loading File:  ../data/ShimmerData/P2345/P2345.shm\n",
      "Loading File:  ../data/ShimmerData/P2346/P2346.shm\n",
      "Loading File:  ../data/ShimmerData/P2347/P2347.shm\n",
      "Loading File:  ../data/ShimmerData/P2348/P2348.shm\n",
      "Loading File:  ../data/ShimmerData/P2350/P2350.shm\n",
      "Loading File:  ../data/ShimmerData/P2351/P2351.shm\n",
      "Loading File:  ../data/ShimmerData/P2352/P2352.shm\n",
      "Loading File:  ../data/ShimmerData/P2353/P2353.shm\n",
      "Loading File:  ../data/ShimmerData/P2354/P2354.shm\n",
      "Loading File:  ../data/ShimmerData/P2356/P2356.shm\n",
      "Loading File:  ../data/ShimmerData/P2357/P2357.shm\n",
      "Loading File:  ../data/ShimmerData/P2358/P2358.shm\n",
      "Loading File:  ../data/ShimmerData/P2359/P2359.shm\n",
      "Loading File:  ../data/ShimmerData/P2360/P2360.shm\n",
      "Loading File:  ../data/ShimmerData/P2361/P2361.shm\n",
      "Loading File:  ../data/ShimmerData/P2362/P2362.shm\n",
      "Loading File:  ../data/ShimmerData/P2363/P2363.shm\n",
      "Loading File:  ../data/ShimmerData/P2364/P2364.shm\n",
      "Loading File:  ../data/ShimmerData/P2365/P2365.shm\n",
      "Loading File:  ../data/ShimmerData/P2366/P2366.shm\n",
      "Loading File:  ../data/ShimmerData/P2367/P2367.shm\n",
      "Loading File:  ../data/ShimmerData/P2368/P2368.shm\n",
      "Loading File:  ../data/ShimmerData/P2369/P2369.shm\n",
      "Loading File:  ../data/ShimmerData/P2370/P2370.shm\n",
      "Loading File:  ../data/ShimmerData/P2373/P2373.shm\n",
      "Loading File:  ../data/ShimmerData/P2374/P2374.shm\n",
      "Loading File:  ../data/ShimmerData/P2375/P2375.shm\n",
      "Loading File:  ../data/ShimmerData/P2377/P2377.shm\n",
      "Loading File:  ../data/ShimmerData/P2378/P2378.shm\n",
      "Loading File:  ../data/ShimmerData/P2379/P2379.shm\n",
      "Loading File:  ../data/ShimmerData/P2380/P2380.shm\n",
      "Loading File:  ../data/ShimmerData/P2381/P2381.shm\n",
      "Loading File:  ../data/ShimmerData/P2382/P2382.shm\n",
      "Loading File:  ../data/ShimmerData/P2383/P2383.shm\n",
      "Loading File:  ../data/ShimmerData/P2384/P2384.shm\n",
      "Loading File:  ../data/ShimmerData/P2386/P2386.shm\n",
      "Loading File:  ../data/ShimmerData/P2387/P2387.shm\n",
      "Loading File:  ../data/ShimmerData/P2388/P2388.shm\n",
      "Loading File:  ../data/ShimmerData/P2390/P2390.shm\n",
      "Loading File:  ../data/ShimmerData/P2391/P2391.shm\n",
      "Loading File:  ../data/ShimmerData/P2392/P2392.shm\n",
      "Loading File:  ../data/ShimmerData/P2394/P2394.shm\n",
      "Loading File:  ../data/ShimmerData/P2395/P2395.shm\n",
      "Loading File:  ../data/ShimmerData/P2396/P2396.shm\n",
      "Loading File:  ../data/ShimmerData/P2398/P2398.shm\n",
      "Loading File:  ../data/ShimmerData/P2399/P2399.shm\n",
      "Loading File:  ../data/ShimmerData/P2401/P2401.shm\n",
      "Loading File:  ../data/ShimmerData/P2402/P2402.shm\n",
      "Loading File:  ../data/ShimmerData/P2403/P2403.shm\n",
      "Loading File:  ../data/ShimmerData/P2406/P2406.shm\n",
      "Loading File:  ../data/ShimmerData/P2407/P2407.shm\n",
      "Loading File:  ../data/ShimmerData/P2408/P2408.shm\n",
      "Loading File:  ../data/ShimmerData/P2409/P2409.shm\n",
      "Loading File:  ../data/ShimmerData/P2410/P2410.shm\n",
      "Loading File:  ../data/ShimmerData/P2413/P2413.shm\n",
      "Loading File:  ../data/ShimmerData/P2415/P2415.shm\n",
      "Loading File:  ../data/ShimmerData/P2416/P2416.shm\n",
      "Loading File:  ../data/ShimmerData/P2417/P2417.shm\n",
      "Loading File:  ../data/ShimmerData/P2418/P2418.shm\n",
      "Loading File:  ../data/ShimmerData/P2419/P2419.shm\n",
      "Loading File:  ../data/ShimmerData/P2421/P2421.shm\n",
      "Loading File:  ../data/ShimmerData/P2422/P2422.shm\n",
      "Loading File:  ../data/ShimmerData/P2423/P2423.shm\n",
      "Loading File:  ../data/ShimmerData/P2424/P2424.shm\n",
      "Loading File:  ../data/ShimmerData/P2425/P2425.shm\n",
      "Loading File:  ../data/ShimmerData/P2426/P2426.shm\n",
      "Loading File:  ../data/ShimmerData/P2427/P2427.shm\n",
      "Loading File:  ../data/ShimmerData/P2428/P2428.shm\n",
      "Loading File:  ../data/ShimmerData/P2429/P2429.shm\n",
      "Loading File:  ../data/ShimmerData/P2430/P2430.shm\n",
      "Loading File:  ../data/ShimmerData/P2432/P2432.shm\n",
      "Loading File:  ../data/ShimmerData/P2434/P2434.shm\n",
      "Loading File:  ../data/ShimmerData/P2436/P2436.shm\n",
      "Loading File:  ../data/ShimmerData/P2437/P2437.shm\n",
      "Loading File:  ../data/ShimmerData/P2438/P2438.shm\n",
      "Loading File:  ../data/ShimmerData/P2440/P2440.shm\n",
      "Loading File:  ../data/ShimmerData/P2442/P2442.shm\n",
      "Loading File:  ../data/ShimmerData/P2443/P2443.shm\n",
      "Loading File:  ../data/ShimmerData/P2444/P2444.shm\n",
      "Loading File:  ../data/ShimmerData/P2446/P2446.shm\n",
      "Loading File:  ../data/ShimmerData/P2447/P2447.shm\n",
      "Loading File:  ../data/ShimmerData/P2449/P2449.shm\n",
      "Loading File:  ../data/ShimmerData/P2451/P2451.shm\n",
      "Loading File:  ../data/ShimmerData/P2452/P2452.shm\n",
      "Loading File:  ../data/ShimmerData/P2453/P2453.shm\n",
      "Loading File:  ../data/ShimmerData/P2454/P2454.shm\n",
      "Loading File:  ../data/ShimmerData/P2455/P2455.shm\n",
      "Loading File:  ../data/ShimmerData/P2456/P2456.shm\n",
      "Loading File:  ../data/ShimmerData/P2457/P2457.shm\n",
      "Loading File:  ../data/ShimmerData/P2458/P2458.shm\n",
      "Loading File:  ../data/ShimmerData/P2459/P2459.shm\n",
      "Loading File:  ../data/ShimmerData/P2460/P2460.shm\n",
      "Loading File:  ../data/ShimmerData/P2461/P2461.shm\n",
      "Loading File:  ../data/ShimmerData/P2462/P2462.shm\n",
      "Loading File:  ../data/ShimmerData/P2463/P2463.shm\n",
      "Loading File:  ../data/ShimmerData/P2464/P2464.shm\n",
      "Loading File:  ../data/ShimmerData/P2465/P2465.shm\n",
      "Loading File:  ../data/ShimmerData/P2466/P2466.shm\n",
      "Loading File:  ../data/ShimmerData/P2467/P2467.shm\n",
      "Loading File:  ../data/ShimmerData/P2468/P2468.shm\n",
      "Loading File:  ../data/ShimmerData/P2469/P2469.shm\n",
      "Loading File:  ../data/ShimmerData/P2470/P2470.shm\n",
      "Loading File:  ../data/ShimmerData/P2471/P2471.shm\n",
      "Loading File:  ../data/ShimmerData/P2474/P2474.shm\n",
      "Loading File:  ../data/ShimmerData/P2475/P2475.shm\n",
      "Loading File:  ../data/ShimmerData/P2476/P2476.shm\n",
      "Loading File:  ../data/ShimmerData/P2477/P2477.shm\n",
      "Loading File:  ../data/ShimmerData/P2478/P2478.shm\n",
      "Loading File:  ../data/ShimmerData/P2479/P2479.shm\n",
      "Loading File:  ../data/ShimmerData/P2481/P2481.shm\n",
      "Loading File:  ../data/ShimmerData/P2482/P2482.shm\n",
      "Loading File:  ../data/ShimmerData/P2483/P2483.shm\n",
      "Loading File:  ../data/ShimmerData/P2484/P2484.shm\n",
      "Train set size: 2706319, with 144317 positive samples and 2562002 negative samples\n",
      "Test set size: 676580, with 36079 positive samples and 640501 negative samples\n",
      "Test Accuracy: None\n",
      "Recall Accuracy: None\n",
      "Test Accuracy: 0.77677\n",
      "Recall Accuracy: 0.67194\n",
      "Test Accuracy: 0.75852\n",
      "Recall Accuracy: 0.69825\n"
     ]
    }
   ],
   "source": [
    "meal_info, performance = test_models(winmin=1, stridesec = 5,names= [\"wenkanw\",\"adam\",\"lawler\",\"shaurya\",\"CAD\"],random_seed=1000, split_day=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Days</th>\n",
       "      <th>Meal_Hours</th>\n",
       "      <th>Meal_Counts</th>\n",
       "      <th>Total_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>354</td>\n",
       "      <td>250</td>\n",
       "      <td>1063</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  Days  Meal_Hours  Meal_Counts  Total_Hours\n",
       "0  wenkanw    17           7           32          129\n",
       "1     adam    20           4           36          168\n",
       "2   lawler    23          25           61          173\n",
       "3  shaurya     6           3           17           65\n",
       "4      CAD   354         250         1063         4680"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>win(sec)</th>\n",
       "      <th>Acc: Individual-Model</th>\n",
       "      <th>Recall: Individual-Model</th>\n",
       "      <th>F1: Individual-Model</th>\n",
       "      <th>Acc: W-GroupModel</th>\n",
       "      <th>Recall: W-GroupModel</th>\n",
       "      <th>F1: W-GroupModel</th>\n",
       "      <th>Acc: S-GroupModel</th>\n",
       "      <th>Recall: S-GroupModel</th>\n",
       "      <th>F1: S-GroupModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>60</td>\n",
       "      <td>0.92780</td>\n",
       "      <td>0.93141</td>\n",
       "      <td>0.92806</td>\n",
       "      <td>0.69449</td>\n",
       "      <td>0.46029</td>\n",
       "      <td>0.60106</td>\n",
       "      <td>0.74639</td>\n",
       "      <td>0.57310</td>\n",
       "      <td>0.69323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95434</td>\n",
       "      <td>0.98353</td>\n",
       "      <td>0.95564</td>\n",
       "      <td>0.82784</td>\n",
       "      <td>0.71257</td>\n",
       "      <td>0.80541</td>\n",
       "      <td>0.79566</td>\n",
       "      <td>0.68413</td>\n",
       "      <td>0.77001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>60</td>\n",
       "      <td>0.84309</td>\n",
       "      <td>0.79048</td>\n",
       "      <td>0.83438</td>\n",
       "      <td>0.65371</td>\n",
       "      <td>0.52882</td>\n",
       "      <td>0.60429</td>\n",
       "      <td>0.65416</td>\n",
       "      <td>0.58188</td>\n",
       "      <td>0.62722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>60</td>\n",
       "      <td>0.83569</td>\n",
       "      <td>0.75088</td>\n",
       "      <td>0.82046</td>\n",
       "      <td>0.66784</td>\n",
       "      <td>0.36926</td>\n",
       "      <td>0.52645</td>\n",
       "      <td>0.67933</td>\n",
       "      <td>0.43110</td>\n",
       "      <td>0.57344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57344</td>\n",
       "      <td>0.77677</td>\n",
       "      <td>0.67194</td>\n",
       "      <td>0.75063</td>\n",
       "      <td>0.75852</td>\n",
       "      <td>0.69825</td>\n",
       "      <td>0.74303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  win(sec)  Acc: Individual-Model  Recall: Individual-Model  \\\n",
       "0  wenkanw        60                0.92780                   0.93141   \n",
       "1     adam        60                0.95434                   0.98353   \n",
       "2   lawler        60                0.84309                   0.79048   \n",
       "3  shaurya        60                0.83569                   0.75088   \n",
       "4      CAD        60                    NaN                       NaN   \n",
       "\n",
       "   F1: Individual-Model  Acc: W-GroupModel  Recall: W-GroupModel  \\\n",
       "0               0.92806            0.69449               0.46029   \n",
       "1               0.95564            0.82784               0.71257   \n",
       "2               0.83438            0.65371               0.52882   \n",
       "3               0.82046            0.66784               0.36926   \n",
       "4               0.57344            0.77677               0.67194   \n",
       "\n",
       "   F1: W-GroupModel  Acc: S-GroupModel  Recall: S-GroupModel  F1: S-GroupModel  \n",
       "0           0.60106            0.74639               0.57310           0.69323  \n",
       "1           0.80541            0.79566               0.68413           0.77001  \n",
       "2           0.60429            0.65416               0.58188           0.62722  \n",
       "3           0.52645            0.67933               0.43110           0.57344  \n",
       "4           0.75063            0.75852               0.69825           0.74303  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "Test Accuracy: 0.80493\n",
      "Recall Accuracy: 0.66847\n",
      "Test Accuracy: 0.62259\n",
      "Recall Accuracy: 0.31611\n",
      "Test Accuracy: 0.68042\n",
      "Recall Accuracy: 0.45875\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Test Accuracy: 0.92225\n",
      "Recall Accuracy: 0.86722\n",
      "Test Accuracy: 0.95036\n",
      "Recall Accuracy: 0.94019\n",
      "Test Accuracy: 0.9372\n",
      "Recall Accuracy: 0.96651\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.14/11.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.10/10.10.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.2/11.2.shm\n",
      "Test Accuracy: 0.77284\n",
      "Recall Accuracy: 0.71965\n",
      "Test Accuracy: 0.70088\n",
      "Recall Accuracy: 0.65457\n",
      "Test Accuracy: 0.68899\n",
      "Recall Accuracy: 0.66708\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "Test Accuracy: 0.48\n",
      "Recall Accuracy: 0.12667\n",
      "Test Accuracy: 0.525\n",
      "Recall Accuracy: 0.1\n",
      "Test Accuracy: 0.54833\n",
      "Recall Accuracy: 0.17333\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/ShimmerData/P2396/P2396.shm\n",
      "Loading File:  ../data/ShimmerData/P2398/P2398.shm\n",
      "Loading File:  ../data/ShimmerData/P2399/P2399.shm\n",
      "Loading File:  ../data/ShimmerData/P2401/P2401.shm\n",
      "Loading File:  ../data/ShimmerData/P2402/P2402.shm\n",
      "Loading File:  ../data/ShimmerData/P2403/P2403.shm\n",
      "Loading File:  ../data/ShimmerData/P2406/P2406.shm\n",
      "Loading File:  ../data/ShimmerData/P2407/P2407.shm\n",
      "Loading File:  ../data/ShimmerData/P2408/P2408.shm\n",
      "Loading File:  ../data/ShimmerData/P2409/P2409.shm\n",
      "Loading File:  ../data/ShimmerData/P2410/P2410.shm\n",
      "Loading File:  ../data/ShimmerData/P2413/P2413.shm\n",
      "Loading File:  ../data/ShimmerData/P2415/P2415.shm\n",
      "Loading File:  ../data/ShimmerData/P2416/P2416.shm\n",
      "Loading File:  ../data/ShimmerData/P2417/P2417.shm\n",
      "Loading File:  ../data/ShimmerData/P2418/P2418.shm\n",
      "Loading File:  ../data/ShimmerData/P2419/P2419.shm\n",
      "Loading File:  ../data/ShimmerData/P2421/P2421.shm\n",
      "Loading File:  ../data/ShimmerData/P2422/P2422.shm\n",
      "Loading File:  ../data/ShimmerData/P2423/P2423.shm\n",
      "Loading File:  ../data/ShimmerData/P2424/P2424.shm\n",
      "Loading File:  ../data/ShimmerData/P2425/P2425.shm\n",
      "Loading File:  ../data/ShimmerData/P2426/P2426.shm\n",
      "Loading File:  ../data/ShimmerData/P2427/P2427.shm\n",
      "Loading File:  ../data/ShimmerData/P2428/P2428.shm\n",
      "Loading File:  ../data/ShimmerData/P2429/P2429.shm\n",
      "Loading File:  ../data/ShimmerData/P2430/P2430.shm\n",
      "Loading File:  ../data/ShimmerData/P2432/P2432.shm\n",
      "Loading File:  ../data/ShimmerData/P2434/P2434.shm\n",
      "Loading File:  ../data/ShimmerData/P2436/P2436.shm\n",
      "Loading File:  ../data/ShimmerData/P2437/P2437.shm\n",
      "Loading File:  ../data/ShimmerData/P2438/P2438.shm\n",
      "Loading File:  ../data/ShimmerData/P2440/P2440.shm\n",
      "Loading File:  ../data/ShimmerData/P2442/P2442.shm\n",
      "Loading File:  ../data/ShimmerData/P2443/P2443.shm\n",
      "Loading File:  ../data/ShimmerData/P2444/P2444.shm\n",
      "Loading File:  ../data/ShimmerData/P2446/P2446.shm\n",
      "Loading File:  ../data/ShimmerData/P2447/P2447.shm\n",
      "Loading File:  ../data/ShimmerData/P2449/P2449.shm\n",
      "Loading File:  ../data/ShimmerData/P2451/P2451.shm\n",
      "Loading File:  ../data/ShimmerData/P2452/P2452.shm\n",
      "Loading File:  ../data/ShimmerData/P2453/P2453.shm\n",
      "Loading File:  ../data/ShimmerData/P2454/P2454.shm\n",
      "Loading File:  ../data/ShimmerData/P2455/P2455.shm\n",
      "Loading File:  ../data/ShimmerData/P2456/P2456.shm\n",
      "Loading File:  ../data/ShimmerData/P2457/P2457.shm\n",
      "Loading File:  ../data/ShimmerData/P2458/P2458.shm\n",
      "Loading File:  ../data/ShimmerData/P2459/P2459.shm\n",
      "Loading File:  ../data/ShimmerData/P2460/P2460.shm\n",
      "Loading File:  ../data/ShimmerData/P2461/P2461.shm\n",
      "Loading File:  ../data/ShimmerData/P2462/P2462.shm\n",
      "Loading File:  ../data/ShimmerData/P2463/P2463.shm\n",
      "Loading File:  ../data/ShimmerData/P2464/P2464.shm\n",
      "Loading File:  ../data/ShimmerData/P2465/P2465.shm\n",
      "Loading File:  ../data/ShimmerData/P2466/P2466.shm\n",
      "Loading File:  ../data/ShimmerData/P2467/P2467.shm\n",
      "Loading File:  ../data/ShimmerData/P2468/P2468.shm\n",
      "Loading File:  ../data/ShimmerData/P2469/P2469.shm\n",
      "Loading File:  ../data/ShimmerData/P2470/P2470.shm\n",
      "Loading File:  ../data/ShimmerData/P2471/P2471.shm\n",
      "Loading File:  ../data/ShimmerData/P2474/P2474.shm\n",
      "Loading File:  ../data/ShimmerData/P2475/P2475.shm\n",
      "Loading File:  ../data/ShimmerData/P2476/P2476.shm\n",
      "Loading File:  ../data/ShimmerData/P2477/P2477.shm\n",
      "Loading File:  ../data/ShimmerData/P2478/P2478.shm\n",
      "Loading File:  ../data/ShimmerData/P2479/P2479.shm\n",
      "Loading File:  ../data/ShimmerData/P2481/P2481.shm\n",
      "Loading File:  ../data/ShimmerData/P2482/P2482.shm\n",
      "Loading File:  ../data/ShimmerData/P2483/P2483.shm\n",
      "Loading File:  ../data/ShimmerData/P2484/P2484.shm\n",
      "Test Accuracy: None\n",
      "Recall Accuracy: None\n",
      "Test Accuracy: 0.77561\n",
      "Recall Accuracy: 0.67266\n",
      "Test Accuracy: 0.75316\n",
      "Recall Accuracy: 0.69103\n"
     ]
    }
   ],
   "source": [
    "meal_info_split_day, performance_split_day = test_models(winmin=1, stridesec = 5,names= [\"wenkanw\",\"adam\",\"lawler\",\"shaurya\",\"CAD\"],random_seed=1000, split_day=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Days</th>\n",
       "      <th>Meal_Hours</th>\n",
       "      <th>Meal_Counts</th>\n",
       "      <th>Total_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>354</td>\n",
       "      <td>250</td>\n",
       "      <td>1063</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  Days  Meal_Hours  Meal_Counts  Total_Hours\n",
       "0  wenkanw    17           7           32          129\n",
       "1     adam    20           4           36          168\n",
       "2   lawler    23          25           61          173\n",
       "3  shaurya     6           3           17           65\n",
       "4      CAD   354         250         1063         4680"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meal_info_split_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>win(sec)</th>\n",
       "      <th>Acc: Individual-Model</th>\n",
       "      <th>Recall: Individual-Model</th>\n",
       "      <th>F1: Individual-Model</th>\n",
       "      <th>Acc: W-GroupModel</th>\n",
       "      <th>Recall: W-GroupModel</th>\n",
       "      <th>F1: W-GroupModel</th>\n",
       "      <th>Acc: S-GroupModel</th>\n",
       "      <th>Recall: S-GroupModel</th>\n",
       "      <th>F1: S-GroupModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>60</td>\n",
       "      <td>0.80493</td>\n",
       "      <td>0.66847</td>\n",
       "      <td>0.77411</td>\n",
       "      <td>0.62259</td>\n",
       "      <td>0.31611</td>\n",
       "      <td>0.45581</td>\n",
       "      <td>0.68042</td>\n",
       "      <td>0.45875</td>\n",
       "      <td>0.58940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>0.92225</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.91772</td>\n",
       "      <td>0.95036</td>\n",
       "      <td>0.94019</td>\n",
       "      <td>0.94985</td>\n",
       "      <td>0.93720</td>\n",
       "      <td>0.96651</td>\n",
       "      <td>0.93899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>60</td>\n",
       "      <td>0.77284</td>\n",
       "      <td>0.71965</td>\n",
       "      <td>0.76008</td>\n",
       "      <td>0.70088</td>\n",
       "      <td>0.65457</td>\n",
       "      <td>0.68635</td>\n",
       "      <td>0.68899</td>\n",
       "      <td>0.66708</td>\n",
       "      <td>0.68202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>60</td>\n",
       "      <td>0.48000</td>\n",
       "      <td>0.12667</td>\n",
       "      <td>0.19588</td>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.17391</td>\n",
       "      <td>0.54833</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.27733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27733</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.67266</td>\n",
       "      <td>0.74986</td>\n",
       "      <td>0.75316</td>\n",
       "      <td>0.69103</td>\n",
       "      <td>0.73681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  win(sec)  Acc: Individual-Model  Recall: Individual-Model  \\\n",
       "0  wenkanw        60                0.80493                   0.66847   \n",
       "1     adam        60                0.92225                   0.86722   \n",
       "2   lawler        60                0.77284                   0.71965   \n",
       "3  shaurya        60                0.48000                   0.12667   \n",
       "4      CAD        60                    NaN                       NaN   \n",
       "\n",
       "   F1: Individual-Model  Acc: W-GroupModel  Recall: W-GroupModel  \\\n",
       "0               0.77411            0.62259               0.31611   \n",
       "1               0.91772            0.95036               0.94019   \n",
       "2               0.76008            0.70088               0.65457   \n",
       "3               0.19588            0.52500               0.10000   \n",
       "4               0.27733            0.77561               0.67266   \n",
       "\n",
       "   F1: W-GroupModel  Acc: S-GroupModel  Recall: S-GroupModel  F1: S-GroupModel  \n",
       "0           0.45581            0.68042               0.45875           0.58940  \n",
       "1           0.94985            0.93720               0.96651           0.93899  \n",
       "2           0.68635            0.68899               0.66708           0.68202  \n",
       "3           0.17391            0.54833               0.17333           0.27733  \n",
       "4           0.74986            0.75316               0.69103           0.73681  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_split_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-14-20/11-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-13-20/10-13-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-9-20/10-10-20.shm\n",
      "Test Accuracy: 0.80493\n",
      "Recall Accuracy: 0.66847\n",
      "AUC Score: 0.80493\n",
      "Test Accuracy: 0.62259\n",
      "Recall Accuracy: 0.31611\n",
      "AUC Score: 0.62259\n",
      "Test Accuracy: 0.68042\n",
      "Recall Accuracy: 0.45875\n",
      "AUC Score: 0.68042\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Test Accuracy: 0.92225\n",
      "Recall Accuracy: 0.86722\n",
      "AUC Score: 0.92225\n",
      "Test Accuracy: 0.95036\n",
      "Recall Accuracy: 0.94019\n",
      "AUC Score: 0.95036\n",
      "Test Accuracy: 0.9372\n",
      "Recall Accuracy: 0.96651\n",
      "AUC Score: 0.9372\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.14/11.14.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.10/10.10.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/11.2/11.2.shm\n",
      "Test Accuracy: 0.77284\n",
      "Recall Accuracy: 0.71965\n",
      "AUC Score: 0.77284\n",
      "Test Accuracy: 0.70088\n",
      "Recall Accuracy: 0.65457\n",
      "AUC Score: 0.70088\n",
      "Test Accuracy: 0.68899\n",
      "Recall Accuracy: 0.66708\n",
      "AUC Score: 0.68899\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/10.25.2020/Data.shm\n",
      "Test Accuracy: 0.48\n",
      "Recall Accuracy: 0.12667\n",
      "AUC Score: 0.48\n",
      "Test Accuracy: 0.525\n",
      "Recall Accuracy: 0.1\n",
      "AUC Score: 0.525\n",
      "Test Accuracy: 0.54833\n",
      "Recall Accuracy: 0.17333\n",
      "AUC Score: 0.54833\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/ShimmerData/P2396/P2396.shm\n",
      "Loading File:  ../data/ShimmerData/P2398/P2398.shm\n",
      "Loading File:  ../data/ShimmerData/P2399/P2399.shm\n",
      "Loading File:  ../data/ShimmerData/P2401/P2401.shm\n",
      "Loading File:  ../data/ShimmerData/P2402/P2402.shm\n",
      "Loading File:  ../data/ShimmerData/P2403/P2403.shm\n",
      "Loading File:  ../data/ShimmerData/P2406/P2406.shm\n",
      "Loading File:  ../data/ShimmerData/P2407/P2407.shm\n",
      "Loading File:  ../data/ShimmerData/P2408/P2408.shm\n",
      "Loading File:  ../data/ShimmerData/P2409/P2409.shm\n",
      "Loading File:  ../data/ShimmerData/P2410/P2410.shm\n",
      "Loading File:  ../data/ShimmerData/P2413/P2413.shm\n",
      "Loading File:  ../data/ShimmerData/P2415/P2415.shm\n",
      "Loading File:  ../data/ShimmerData/P2416/P2416.shm\n",
      "Loading File:  ../data/ShimmerData/P2417/P2417.shm\n",
      "Loading File:  ../data/ShimmerData/P2418/P2418.shm\n",
      "Loading File:  ../data/ShimmerData/P2419/P2419.shm\n",
      "Loading File:  ../data/ShimmerData/P2421/P2421.shm\n",
      "Loading File:  ../data/ShimmerData/P2422/P2422.shm\n",
      "Loading File:  ../data/ShimmerData/P2423/P2423.shm\n",
      "Loading File:  ../data/ShimmerData/P2424/P2424.shm\n",
      "Loading File:  ../data/ShimmerData/P2425/P2425.shm\n",
      "Loading File:  ../data/ShimmerData/P2426/P2426.shm\n",
      "Loading File:  ../data/ShimmerData/P2427/P2427.shm\n",
      "Loading File:  ../data/ShimmerData/P2428/P2428.shm\n",
      "Loading File:  ../data/ShimmerData/P2429/P2429.shm\n",
      "Loading File:  ../data/ShimmerData/P2430/P2430.shm\n",
      "Loading File:  ../data/ShimmerData/P2432/P2432.shm\n",
      "Loading File:  ../data/ShimmerData/P2434/P2434.shm\n",
      "Loading File:  ../data/ShimmerData/P2436/P2436.shm\n",
      "Loading File:  ../data/ShimmerData/P2437/P2437.shm\n",
      "Loading File:  ../data/ShimmerData/P2438/P2438.shm\n",
      "Loading File:  ../data/ShimmerData/P2440/P2440.shm\n",
      "Loading File:  ../data/ShimmerData/P2442/P2442.shm\n",
      "Loading File:  ../data/ShimmerData/P2443/P2443.shm\n",
      "Loading File:  ../data/ShimmerData/P2444/P2444.shm\n",
      "Loading File:  ../data/ShimmerData/P2446/P2446.shm\n",
      "Loading File:  ../data/ShimmerData/P2447/P2447.shm\n",
      "Loading File:  ../data/ShimmerData/P2449/P2449.shm\n",
      "Loading File:  ../data/ShimmerData/P2451/P2451.shm\n",
      "Loading File:  ../data/ShimmerData/P2452/P2452.shm\n",
      "Loading File:  ../data/ShimmerData/P2453/P2453.shm\n",
      "Loading File:  ../data/ShimmerData/P2454/P2454.shm\n",
      "Loading File:  ../data/ShimmerData/P2455/P2455.shm\n",
      "Loading File:  ../data/ShimmerData/P2456/P2456.shm\n",
      "Loading File:  ../data/ShimmerData/P2457/P2457.shm\n",
      "Loading File:  ../data/ShimmerData/P2458/P2458.shm\n",
      "Loading File:  ../data/ShimmerData/P2459/P2459.shm\n",
      "Loading File:  ../data/ShimmerData/P2460/P2460.shm\n",
      "Loading File:  ../data/ShimmerData/P2461/P2461.shm\n",
      "Loading File:  ../data/ShimmerData/P2462/P2462.shm\n",
      "Loading File:  ../data/ShimmerData/P2463/P2463.shm\n",
      "Loading File:  ../data/ShimmerData/P2464/P2464.shm\n",
      "Loading File:  ../data/ShimmerData/P2465/P2465.shm\n",
      "Loading File:  ../data/ShimmerData/P2466/P2466.shm\n",
      "Loading File:  ../data/ShimmerData/P2467/P2467.shm\n",
      "Loading File:  ../data/ShimmerData/P2468/P2468.shm\n",
      "Loading File:  ../data/ShimmerData/P2469/P2469.shm\n",
      "Loading File:  ../data/ShimmerData/P2470/P2470.shm\n",
      "Loading File:  ../data/ShimmerData/P2471/P2471.shm\n",
      "Loading File:  ../data/ShimmerData/P2474/P2474.shm\n",
      "Loading File:  ../data/ShimmerData/P2475/P2475.shm\n",
      "Loading File:  ../data/ShimmerData/P2476/P2476.shm\n",
      "Loading File:  ../data/ShimmerData/P2477/P2477.shm\n",
      "Loading File:  ../data/ShimmerData/P2478/P2478.shm\n",
      "Loading File:  ../data/ShimmerData/P2479/P2479.shm\n",
      "Loading File:  ../data/ShimmerData/P2481/P2481.shm\n",
      "Loading File:  ../data/ShimmerData/P2482/P2482.shm\n",
      "Loading File:  ../data/ShimmerData/P2483/P2483.shm\n",
      "Loading File:  ../data/ShimmerData/P2484/P2484.shm\n",
      "Test Accuracy: None\n",
      "Recall Accuracy: None\n",
      "AUC Score: None\n",
      "Test Accuracy: 0.77561\n",
      "Recall Accuracy: 0.67266\n",
      "AUC Score: 0.77561\n",
      "Test Accuracy: 0.75316\n",
      "Recall Accuracy: 0.69103\n",
      "AUC Score: 0.75316\n"
     ]
    }
   ],
   "source": [
    "meal_info_split_day, performance_split_day = test_models(winmin=1, stridesec = 5,names= [\"wenkanw\",\"adam\",\"lawler\",\"shaurya\",\"CAD\"],random_seed=1000, split_day=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Days</th>\n",
       "      <th>Meal_Hours</th>\n",
       "      <th>Meal_Counts</th>\n",
       "      <th>Total_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>354</td>\n",
       "      <td>250</td>\n",
       "      <td>1063</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  Days  Meal_Hours  Meal_Counts  Total_Hours\n",
       "0  wenkanw    17           7           32          129\n",
       "1     adam    20           4           36          168\n",
       "2   lawler    23          25           61          173\n",
       "3  shaurya     6           3           17           65\n",
       "4      CAD   354         250         1063         4680"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meal_info_split_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>win(sec)</th>\n",
       "      <th>Acc: Individual-Model</th>\n",
       "      <th>Recall: Individual-Model</th>\n",
       "      <th>Auc: Individual-Model</th>\n",
       "      <th>Acc: W-GroupModel</th>\n",
       "      <th>Recall: W-GroupModel</th>\n",
       "      <th>Auc: W-GroupModel</th>\n",
       "      <th>Acc: S-GroupModel</th>\n",
       "      <th>Recall: S-GroupModel</th>\n",
       "      <th>Auc: S-GroupModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>60</td>\n",
       "      <td>0.80493</td>\n",
       "      <td>0.66847</td>\n",
       "      <td>0.80493</td>\n",
       "      <td>0.62259</td>\n",
       "      <td>0.31611</td>\n",
       "      <td>0.62259</td>\n",
       "      <td>0.68042</td>\n",
       "      <td>0.45875</td>\n",
       "      <td>0.68042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>0.92225</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.92225</td>\n",
       "      <td>0.95036</td>\n",
       "      <td>0.94019</td>\n",
       "      <td>0.95036</td>\n",
       "      <td>0.93720</td>\n",
       "      <td>0.96651</td>\n",
       "      <td>0.93720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>60</td>\n",
       "      <td>0.77284</td>\n",
       "      <td>0.71965</td>\n",
       "      <td>0.77284</td>\n",
       "      <td>0.70088</td>\n",
       "      <td>0.65457</td>\n",
       "      <td>0.70088</td>\n",
       "      <td>0.68899</td>\n",
       "      <td>0.66708</td>\n",
       "      <td>0.68899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>60</td>\n",
       "      <td>0.48000</td>\n",
       "      <td>0.12667</td>\n",
       "      <td>0.48000</td>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.54833</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.54833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.67266</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.75316</td>\n",
       "      <td>0.69103</td>\n",
       "      <td>0.75316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  win(sec)  Acc: Individual-Model  Recall: Individual-Model  \\\n",
       "0  wenkanw        60                0.80493                   0.66847   \n",
       "1     adam        60                0.92225                   0.86722   \n",
       "2   lawler        60                0.77284                   0.71965   \n",
       "3  shaurya        60                0.48000                   0.12667   \n",
       "4      CAD        60                    NaN                       NaN   \n",
       "\n",
       "   Auc: Individual-Model  Acc: W-GroupModel  Recall: W-GroupModel  \\\n",
       "0                0.80493            0.62259               0.31611   \n",
       "1                0.92225            0.95036               0.94019   \n",
       "2                0.77284            0.70088               0.65457   \n",
       "3                0.48000            0.52500               0.10000   \n",
       "4                    NaN            0.77561               0.67266   \n",
       "\n",
       "   Auc: W-GroupModel  Acc: S-GroupModel  Recall: S-GroupModel  \\\n",
       "0            0.62259            0.68042               0.45875   \n",
       "1            0.95036            0.93720               0.96651   \n",
       "2            0.70088            0.68899               0.66708   \n",
       "3            0.52500            0.54833               0.17333   \n",
       "4            0.77561            0.75316               0.69103   \n",
       "\n",
       "   Auc: S-GroupModel  \n",
       "0            0.68042  \n",
       "1            0.93720  \n",
       "2            0.68899  \n",
       "3            0.54833  \n",
       "4            0.75316  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_split_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./log/wenkanw_model2.pb/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model to pb file\n",
    "# model_path = '../models/wenkanw_models/resnet_M_F_1.000000Min.h5'\n",
    "# model = keras.models.load_model(model_path)\n",
    "# model.save(\"./log/wenkanw_model2.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b126980f68409a875289bfa0e42b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=258711, description='offset', max=517423), Dropdown(description='winsize…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# time_series = np.random.random(10000)\n",
    "\n",
    "# meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5)\n",
    "meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 0,\n",
    "                 normalize_flag = 0)\n",
    "time_series = meal_data.data[0].T\n",
    "\n",
    "# Remove outliers\n",
    "# for i in range(len(time_series)):\n",
    "#     med = np.quantile(time_series[i],[0.5])\n",
    "#     boundary = np.quantile(time_series[i],[0.01,0.99])\n",
    "#     time_series[i][time_series[i]>boundary[1]] = med\n",
    "#     time_series[i][time_series[i]<boundary[0]] = med\n",
    "    \n",
    "def f(offset,winsize,moment):\n",
    "    if moment!= None:\n",
    "        offset = int(moment)\n",
    "    if offset < time_series.shape[1]-winsize:\n",
    "        t = np.arange(start = offset, stop= offset+winsize, step=1)\n",
    "        fig, ax = plt.subplots(3,1,figsize= (20,10))\n",
    "        df1 = time_series[3, offset: offset+winsize]\n",
    "        df2 = time_series[4, offset: offset+winsize]\n",
    "        df3 = time_series[5, offset: offset+winsize]\n",
    "        # set y-axis center at 0\n",
    "        ax[0].set_ylim(-max(abs(df1)),max(abs(df1)))\n",
    "        ax[1].set_ylim(-max(abs(df2)),max(abs(df2)))\n",
    "        ax[2].set_ylim(-max(abs(df3)),max(abs(df3)))\n",
    "        \n",
    "        _ = sns.lineplot(t,df1 , ax =ax[0])\n",
    "        _ = sns.lineplot(t, df2, ax =ax[1])\n",
    "        _ = sns.lineplot(t, df3, ax =ax[2])\n",
    "        \n",
    "    \n",
    "    return \n",
    "interact(f, offset=(0, time_series.shape[1]), winsize= [15*30], moment = '0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n"
     ]
    }
   ],
   "source": [
    "# meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 0,\n",
    "#                  normalize_flag = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.11059570e+02, -4.56250153e+01, -2.53175354e+00,  1.21917725e-02,\n",
       "        2.71726990e+00,  5.33414972e+01,  6.80175781e+02])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = meal_data.data[0].T\n",
    "# num = 2\n",
    "# np.max(df[num]), np.min(df[num]),len(df[df>30]),len(df[df<-20])\n",
    "# num = 3\n",
    "# np.quantile(df[num],[0,0.02,0.25,0.5,0.75,0.98,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n"
     ]
    }
   ],
   "source": [
    "meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 1,\n",
    "                 normalize_flag = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[     0,      0,    900,  42966],\n",
       "        [     0,     75,    975,  42966],\n",
       "        [     0,    150,   1050,  42966],\n",
       "        ...,\n",
       "        [     0, 516300, 517200,  42966],\n",
       "        [     0, 516375, 517275,  42966],\n",
       "        [     0, 516450, 517350,  42966]]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day  = 0\n",
    "day1_data = meal_data.data_indices[meal_data.data_indices[:,0]==day]\n",
    "day1_label = meal_data.labels[meal_data.data_indices[:,0]==day]\n",
    "day1_data, day1_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20266, 20266, {0, 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meal_data.data_indices),len( meal_data.labels),set(day1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6887/6887 [00:16<00:00, 408.38it/s]\n"
     ]
    }
   ],
   "source": [
    "subdataset = meal_data.get_dataset(0, len(day1_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8596,  1.9263,  1.1254, -0.0842,  0.1248, -3.1173],\n",
       "        [-1.0928,  2.8200, -1.6128, -3.7340, -0.8169, -2.9935],\n",
       "        [-0.4306,  4.1507, -1.5634,  0.4042,  0.2284, -1.2990],\n",
       "        ...,\n",
       "        [ 0.1852,  1.2797,  1.0220, -1.7421,  0.5912, -0.3239],\n",
       "        [ 0.1933,  1.5122,  1.3155, -1.6786,  0.4341, -1.1580],\n",
       "        [ 0.2658,  1.8572,  1.5431, -1.4450,  0.1537, -1.1859]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdataset['data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.8908533e-10, 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, label = meal_data[0][0].numpy(),meal_data[0][1]\n",
    "\n",
    "model = tf.keras.models.load_model('../models/'+ 'wenkanw'+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "s2 = np.expand_dims(sample,axis=0)\n",
    "sample.shape, s2.shape, s2[0].all()==sample.all()\n",
    "model(s2).numpy()[0][0],label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6887,  6888,  6889, ..., 13176, 13177, 13178]),)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in set(meal_data.data_indices[:,0]):\n",
    "#     print(i)\n",
    "# day=1\n",
    "# np.where(meal_data.data_indices[:,0]==day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hysteresis threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hysteresis_threshold(model, data,start_threshold=0.8, end_threshold=0.3, winmin = 1,\n",
    "                        stepsec=5, episode_min = 1.,t_pause = 900):\n",
    "    \"\"\"\n",
    "    model: tensorflow model\n",
    "    data:  This dataset must be the self-defined class of Person_MealsDataset  datasetset in my dataset.py/pytorch dataset without using shuffle. \n",
    "    Keep the order of dataset after extracting window samples!  You can also define your own dataset using class object to create the interface\n",
    "    \n",
    "    start_threshold: the high threshold of the beginning of segmentation\n",
    "    \n",
    "    end_threshold: the end threshold of the end of segmentation\n",
    "    \n",
    "    winmin: size of a window sample in unit of  minute\n",
    "    \n",
    "    stepsec: stride to move the window in unit of second / the number of second between two adjacent window samples\n",
    "    \n",
    "    episode_min: the minimum length of eating episode in unit of minute. If end of segmentation -start of segmentation < episode_min,\n",
    "        then the episode will not be counted\n",
    "    \n",
    "    \"\"\"\n",
    "    result_ls = []\n",
    "    \n",
    "    \n",
    "    days = set(data.data_indices[:,0])\n",
    "    for day in days:\n",
    "        # Select and Extract the data and labels of the corresponding day from the whole dataset\n",
    "        sample_indices= np.where(data.data_indices[:,0]==day)[0]\n",
    "        result = {'day':day, 'segment_start':[], 'segment_end':[],'proba':[],'predictions':np.zeros([len(sample_indices)]),'labels':[],\"segment_count\":0}\n",
    "        \n",
    "        # get the numpy array of samples and labels\n",
    "        samples, labels = data.get_subset(sample_indices)\n",
    "        probas = model(samples)\n",
    "        state = 0\n",
    "        start = 0\n",
    "        end = 0 \n",
    "        pause_counter = 0\n",
    "        # one day data\n",
    "        print(\"Day: \",day)\n",
    "        for i in range(len(sample_indices)):\n",
    "            #print(\"i:\",i)\n",
    "            #sample, label = data[i][0].numpy(),data[i][1]\n",
    "            #sample = np.expand_dims(sample,axis=0)\n",
    "            #proba = model(sample).numpy()[0][0]\n",
    "            sample = samples[i]\n",
    "            label = labels[i]\n",
    "            proba = probas[i].numpy()[0]\n",
    "            \n",
    "            result['proba'].append(proba)\n",
    "            result['labels'].append(label)\n",
    "            \n",
    "            if state ==0 and proba > start_threshold:\n",
    "                state = 1\n",
    "                start = i\n",
    "            elif state == 1 and proba <end_threshold:\n",
    "                state = 2\n",
    "                end = i+1\n",
    "                pause_counter = 0\n",
    "            elif state ==2:\n",
    "                if proba > start_threshold:\n",
    "                    state = 1\n",
    "                else:\n",
    "                    pause_counter += stepsec\n",
    "                    if pause_counter >= t_pause:\n",
    "                        # convert time to second and check threshold\n",
    "                        if (end-start)*stepsec >= episode_min*60:\n",
    "                            # save data\n",
    "                            result['segment_start'].append(start)\n",
    "                            result['segment_end'].append(end)\n",
    "                            result['segment_count'] += 1\n",
    "                            result['predictions'][start:end] = 1\n",
    "                            pass\n",
    "                        end = 0\n",
    "                        state = 0\n",
    "        if state != 0:\n",
    "            # if segment ended at the end of data\n",
    "            if end != 0:\n",
    "                result['segment_start'].append(start)\n",
    "                result['segment_end'].append(end)\n",
    "                result['predictions'][start:end] = 1\n",
    "            else:\n",
    "                result['segment_count'] -= 1  \n",
    "            result['segment_count'] += 1\n",
    "            \n",
    "        result_ls.append(result)\n",
    "        print(\"Segmentation Completed. \")\n",
    "                            \n",
    "    return pd.DataFrame(result_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result):\n",
    "    from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    result_df = {\"Day\":[],\"Accuracy\":[],\"Recall\":[],\"AUC\":[]}\n",
    "    for i in range(len(result)):\n",
    "        preds = result.iloc[i]['predictions']\n",
    "        labels =  result.iloc[i]['labels']\n",
    "        #print(\"Day: \", i,\"Sample Num: \", len(preds) , \"Prediction values: \",set(preds),\"Segment Count: \",result.iloc[i]['segment_count'])\n",
    "\n",
    "        acc = accuracy_score(labels,preds)\n",
    "        rec = recall_score(labels,preds)\n",
    "        auc = roc_auc_score(labels,preds)\n",
    "        #print(\"Day-\"+str(i), \" Accuracy: \", acc, \" Recall: \",rec,\"Auc: \",auc)\n",
    "        #print()\n",
    "        result_df[\"Day\"].append(str(i))\n",
    "        result_df[\"Accuracy\"].append(acc)\n",
    "        result_df[\"Recall\"].append(rec)\n",
    "        result_df[\"AUC\"].append(auc)\n",
    "        total_preds.extend(preds)\n",
    "        total_labels.extend(labels)\n",
    "\n",
    "    acc= accuracy_score(total_labels,total_preds)\n",
    "    rec = recall_score(total_labels,total_preds)\n",
    "    auc = roc_auc_score(total_labels,total_preds)\n",
    "    \n",
    "    print(\"All Days: \",\" Accuracy: \", acc, \" Recall: \",rec,\"AUC\",auc)\n",
    "    result_df[\"Day\"].append(\"All Days\")\n",
    "    result_df[\"Accuracy\"].append(acc)\n",
    "    result_df[\"Recall\"].append(rec)\n",
    "    result_df[\"AUC\"].append(auc)\n",
    "    return pd.DataFrame(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segment(labels):\n",
    "    start = []\n",
    "    end = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==1 and (i==0 or labels[i-1]==0):\n",
    "            start.append(i)\n",
    "        if labels[i]==1 and (i ==len(labels)-1 or  labels[i+1] ==0):\n",
    "            end.append(i)\n",
    "        \n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_metrics(result, meal_data =None):\n",
    "    from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    perf = {\"TPR\":[],\"FP/TP\":[],\"TP\":[], \"FP\":[],\"FN\":[]}\n",
    "    tpr = 0. \n",
    "    FP_TP = 0.\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    result_df = {\"Day\":[],\"Accuracy\":[],\"Recall\":[],\"AUC\":[]}\n",
    "    for i in range(len(result)):\n",
    "        preds = result.iloc[i]['predictions']\n",
    "        labels =  result.iloc[i]['labels']\n",
    "        \n",
    "        for index in range(len(result.iloc[i]['segment_start'])):\n",
    "            s = result.iloc[i]['segment_start'][index]\n",
    "            e = result.iloc[i]['segment_end'][index]\n",
    "            if sum(labels[s:e]) >0:\n",
    "                # detect one meal\n",
    "                TP += 1 #e-s + 1\n",
    "            else:\n",
    "                # detect wrongly\n",
    "                FP += 1 #e- s + 1\n",
    "        \n",
    "        labels_start, labels_end =  find_segment(labels)\n",
    "        for index in range(len(labels_start)):\n",
    "            s = labels_start[index]\n",
    "            e = labels_end[index]\n",
    "            # missing meal\n",
    "            if sum(preds[s:e]) == 0:\n",
    "                FN += 1 #e - s + 1\n",
    "            \n",
    "            \n",
    "                \n",
    "    \n",
    "    print(\"TP: \", TP, \"FP: \", FP, \"FN: \", FN)\n",
    "    perf['TPR'].append(TP/(TP+FN))\n",
    "    if TP ==0:\n",
    "        perf['FP/TP'].append(None)\n",
    "    else:\n",
    "        perf['FP/TP'].append(FP/TP)\n",
    "    perf[\"TP\"].append(TP)\n",
    "    perf[\"FP\"].append(FP)\n",
    "    perf[\"FN\"].append(FN)\n",
    "    result_df = pd.DataFrame(perf)\n",
    "        \n",
    "    return pd.DataFrame(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "TP:  9 FP:  5 FN:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR     FP/TP  TP  FP  FN\n",
       "0  1.0  0.555556   9   5   0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = 'adam'\n",
    "meal_data = Person_MealsDataset(person_name= person, file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 1,\n",
    "                 normalize_flag = 1)\n",
    "\n",
    "# meal_data = Person_MealsDataset(person_name= person, file_name = \"all_files_list\", winmin = 1,stridesec = 5,smooth_flag = 1,\n",
    "#                  normalize_flag = 1)\n",
    "model = tf.keras.models.load_model('../models/'+ person + '_models/resnet_M_F_1.000000Min.h5')\n",
    "# model = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "# model = tf.keras.models.load_model('../models/'+ person+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "\n",
    "threshold = {'wenkanw':[0.8, 0.3], 'adam':[0.8,0.3],'lawler':[0.8,0.3], 'shaurya':[0.8,0.3]}\n",
    "# threshold = {'wenkanw':[0.9, 0.3], 'adam':[0.9,0.3],'lawler':[0.9,0.3], 'shaurya':[0.9,0.3]}\n",
    "# threshold = {'wenkanw':[0.8, 0.4], 'adam':[0.8,0.4],'lawler':[0.8,0.4], 'shaurya':[0.8,0.4]}\n",
    "high_th, low_th = threshold[person][0], threshold[person][1]\n",
    "result = hysteresis_threshold(model, meal_data,start_threshold=high_th, end_threshold=low_th, winmin = 1, stepsec=5, episode_min = 1.)\n",
    "episode_perf_df = get_episode_metrics(result)\n",
    "episode_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meal_data.person_name #.get_mealdataset_info(person_name=person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "TP:  9 FP:  7 FN:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR     FP/TP  TP  FP  FN\n",
       "0  1.0  0.777778   9   7   0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "\n",
    "high_th, low_th = threshold[person][0], threshold[person][1]\n",
    "result = hysteresis_threshold(model, meal_data,start_threshold=high_th, end_threshold=low_th, winmin = 1, stepsec=5, episode_min = 1.)\n",
    "episode_perf_df = get_episode_metrics(result)\n",
    "episode_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  60 60\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "cnt2 = 0\n",
    "for i in range(len(result)):\n",
    "    labels =  result.iloc[i]['labels']\n",
    "    labels_start, labels_end =  find_segment(labels)\n",
    "    cnt += len(labels_start)\n",
    "    cnt2 += len(labels_end)\n",
    "print(\"Count: \", cnt,cnt2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "TP:  9 FP:  5 FN:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR     FP/TP  TP  FP  FN\n",
       "0  1.0  0.555556   9   5   0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = 'adam'\n",
    "meal_data = Person_MealsDataset(person_name= person, file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 1,\n",
    "                 normalize_flag = 1)\n",
    "model = tf.keras.models.load_model('../models/'+ person + '_models/resnet_M_F_1.000000Min.h5')\n",
    "\n",
    "threshold = {'wenkanw':[0.8, 0.3], 'adam':[0.8,0.3],'lawler':[0.8,0.3], 'shaurya':[0.8,0.3]}\n",
    "# threshold = {'wenkanw':[0.9, 0.3], 'adam':[0.9,0.3],'lawler':[0.9,0.3], 'shaurya':[0.9,0.3]}\n",
    "# threshold = {'wenkanw':[0.8, 0.4], 'adam':[0.8,0.4],'lawler':[0.8,0.4], 'shaurya':[0.8,0.4]}\n",
    "high_th, low_th = threshold[person][0], threshold[person][1]\n",
    "result = hysteresis_threshold(model, meal_data,start_threshold=high_th, end_threshold=low_th, winmin = 1, stepsec=5, episode_min = 1.)\n",
    "episode_perf_df1 = get_episode_metrics(result)\n",
    "episode_perf_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "TP:  9 FP:  7 FN:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR     FP/TP  TP  FP  FN\n",
       "0  1.0  0.777778   9   7   0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "high_th, low_th = threshold[person][0], threshold[person][1]\n",
    "result = hysteresis_threshold(model, meal_data,start_threshold=high_th, end_threshold=low_th, winmin = 1, stepsec=5, episode_min = 1.)\n",
    "episode_perf_df2 = get_episode_metrics(result)\n",
    "episode_perf_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2084f7b38744fc28f6f5cef66136ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=0, description='offset:[0~8549]', max=8549, style=DescriptionStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# time_series = np.random.random(10000)\n",
    "\n",
    "# meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5)\n",
    "# meal_data = Person_MealsDataset(person_name= \"wenkanw\", file_name = \"test_files\", winmin = 1,stridesec = 5,smooth_flag = 0,\n",
    "#                  normalize_flag = 0)\n",
    "\n",
    "\n",
    "def f(offset,winsize,day):\n",
    "    stride  = 5 *15 # 5 seconds between two adjacent labels/window samples\n",
    "    \n",
    "    day = int(day)\n",
    "    proba = np.array(result.proba.iloc[day])\n",
    "    preds = np.array(result.predictions.iloc[day])\n",
    "    labels = np.array(result.labels.iloc[day])\n",
    "    if winsize == -1:\n",
    "        winsize = len(labels)\n",
    "    \n",
    "    if offset == len(labels)-winsize:\n",
    "        offset = len(labels)-winsize\n",
    "        \n",
    "    t = np.arange(start = offset, stop= offset+winsize, step=1)\n",
    "    fig, ax = plt.subplots(3,1,figsize= (20,12))\n",
    "    df1 = proba[offset:offset+winsize]\n",
    "    df2 = np.array(preds[offset:offset+winsize]) #*10-5\n",
    "    df3 = np.array(labels[offset:offset+winsize])#*10-5\n",
    "    x1= sns.lineplot(x=t, y=df1 , ax =ax[0],color= 'grey',label=\"Possibility\")\n",
    "    x2 = sns.lineplot(t,df2 , ax =ax[1],color='g', linewidth=1.5,label=\"Prediction(Eat)\")\n",
    "    x3 = sns.lineplot(t,df3 , ax =ax[2],color='b', linewidth=1.5, label=\"Label(Eat)\")\n",
    "        \n",
    "    ax[0].fill_between( t, df1, \n",
    "                interpolate=True, color='grey')\n",
    "    \n",
    "    ax[0].fill_between(t, df3, where=(df3==1), \n",
    "                interpolate=True, color='blue')\n",
    "    ax[0].fill_between( t,df2, where=(df2==1), \n",
    "                interpolate=True, color='green')\n",
    "    ax[0].set_ylim(0,1)\n",
    "    print(offset,len(labels)-winsize )\n",
    "    if offset >= len(labels)-winsize:\n",
    "        title_txt =\"Day: \"+ str(day) + \" Whole Day samples: \"+str(len(labels)) +\" . \" + \"Sample plotted: \"+str(winsize)+\". \"\n",
    "    else:\n",
    "        title_txt = \"Day: \"+ str(day) + \"Samples from \"+str(offset) +\"~\" + str((offset+winsize)) +\". \"+ \"Number of Sample plotted: \"+str(winsize)+\". \"\n",
    "    ax[0].set_title(title_txt)\n",
    "    ax[2].set_xlabel(\"index of sample\")\n",
    "    ax[0].set_ylabel(\"Possibility\")\n",
    "    ax[1].set_ylabel(\"Predictions\")\n",
    "    ax[2].set_ylabel(\"Ground Truch\")\n",
    "    \n",
    "    ax[0].legend([\"Possibility\"],loc='upper left')\n",
    "    ax[1].legend([\"1: Eat, 0:Other\"],loc='upper left')\n",
    "    ax[2].legend([\"1: Eat, 0:Other\"],loc='upper left')\n",
    "        \n",
    "    return \n",
    "style = {'description_width': 'initial'}\n",
    "bound_text = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(result.proba.iloc[0]),\n",
    "    step=1,\n",
    "    description='offset:[0~'+ str(len(result.proba.iloc[0]))+\"]\",\n",
    "    disabled=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "slidebar= widgets.IntSlider(min=0, max=len(result.proba.iloc[0]), step=1, value=0)\n",
    "winsize = widgets.Dropdown(\n",
    "    options=[-1, 1000],\n",
    "    value=-1,\n",
    "    description='samples plotted',\n",
    "    disabled=False,\n",
    "    style = style\n",
    ")\n",
    "interact(f, offset=bound_text, winsize= winsize, day = [i for i in range(len(result))]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test_models_hysteresis_threshold(winmin=1, stridesec = 5,names= [\"wenkanw\"],random_seed=1000, test_day=True,thresholds = None,episode_min=1.,high_th = 0.8,low_th= 0.3):\n",
    "    perf = defaultdict(list)\n",
    "    for name in names:\n",
    "        person = name\n",
    "        if test_day:\n",
    "            meal_data = Person_MealsDataset(person_name= person, file_name = \"test_files\", winmin = winmin,stridesec = stridesec,smooth_flag = 1,\n",
    "                         normalize_flag = 1)\n",
    "        else:\n",
    "            meal_data = Person_MealsDataset(person_name= person, file_name = \"all_files_list\", winmin = winmin,stridesec = stridesec,smooth_flag = 1,\n",
    "                         normalize_flag = 1)\n",
    "            \n",
    "#         model = tf.keras.models.load_model('../models/'+ person+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "        \n",
    "        perf[\"dataset\"].append(name)\n",
    "        perf[\"win(sec)\"].append(winmin*60)\n",
    "        \n",
    "            \n",
    "        from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "        group_model_W  = tf.keras.models.load_model('../models/CAD_models/resnet_M_F_1.000000Min.h5')\n",
    "        group_model_S  = tf.keras.models.load_model('../models/ActiModels/CAD_M_F_1.000000Min.h5')\n",
    "        individual_model = tf.keras.models.load_model('../models/'+ name+ '_models/resnet_M_F_1.000000Min.h5')\n",
    "        models = {\"suffix\":['Individual-Model','W-GroupModel',\"S-GroupModel\"],  \"model\":[individual_model,group_model_W,group_model_S]}\n",
    "        \n",
    "        for i in range(len(models[\"suffix\"])):\n",
    "            suffix = models[\"suffix\"][i]\n",
    "            model = models[\"model\"][i]\n",
    "            # if the dataset is CAD group dataset and model is individual model\n",
    "            # we don't need to make prediction on that data\n",
    "            if name == \"CAD\" and suffix =='Individual-Model':\n",
    "                acc = None\n",
    "                auc = None\n",
    "                recall = None\n",
    "            else:\n",
    "                if thresholds != None and person in thresholds.keys():\n",
    "                    high_th, low_th = thresholds[person][0], thresholds[person][1]\n",
    "                \n",
    "                    \n",
    "                result = hysteresis_threshold(model, meal_data,start_threshold=high_th, end_threshold=low_th, winmin = winmin, stepsec=stridesec, episode_min = episode_min)\n",
    "                episode_perf_df = print_results(result)\n",
    "                \n",
    "                acc = episode_perf_df.iloc[-1][\"Accuracy\"]\n",
    "                recall = episode_perf_df.iloc[-1][\"Recall\"]\n",
    "                auc = episode_perf_df.iloc[-1][\"AUC\"]\n",
    "                \n",
    "                acc = round(acc,5)\n",
    "                recall = round(recall, 5)\n",
    "                auc = round(auc,5)\n",
    "            \n",
    "            print(\"Test Accuracy:\", acc)\n",
    "            print(\"Recall Accuracy:\", recall)\n",
    "            print(\"AUC Score:\", auc)\n",
    "            perf[\"Acc: \"+suffix].append(acc)\n",
    "            perf[\"Recall: \"+suffix].append(recall)\n",
    "            perf[\"Auc: \"+suffix].append(auc)\n",
    "\n",
    "    \n",
    "    perf_df = pd.DataFrame(perf)\n",
    "    return  perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/10-14-20/10-14-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/11-18-20/11-18-20.shm\n",
      "Loading File:  ../data/IndividualData/wenkanw-data/9-17-20/9-17-20.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9343234974834699  Recall:  0.9673659673659674 AUC 0.9501143521908155\n",
      "Test Accuracy: 0.93432\n",
      "Recall Accuracy: 0.96737\n",
      "AUC Score: 0.95011\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9585512681338202  Recall:  0.039627039627039624 AUC 0.5194013186593566\n",
      "Test Accuracy: 0.95855\n",
      "Recall Accuracy: 0.03963\n",
      "AUC Score: 0.5194\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9610184545544261  Recall:  0.1247086247086247 AUC 0.5613495720410395\n",
      "Test Accuracy: 0.96102\n",
      "Recall Accuracy: 0.12471\n",
      "AUC Score: 0.56135\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.982041242495432  Recall:  0.8502879078694817 AUC 0.9180064633261759\n",
      "Test Accuracy: 0.98204\n",
      "Recall Accuracy: 0.85029\n",
      "AUC Score: 0.91801\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.977760375880971  Recall:  0.3512476007677543 AUC 0.6732625252953294\n",
      "Test Accuracy: 0.97776\n",
      "Recall Accuracy: 0.35125\n",
      "AUC Score: 0.67326\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9785956669276952  Recall:  0.3397312859884837 AUC 0.6680946866778309\n",
      "Test Accuracy: 0.9786\n",
      "Recall Accuracy: 0.33973\n",
      "AUC Score: 0.66809\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.19/10.19.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.16/10.16.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/9.23/9.23_13hr.shm\n",
      "Loading File:  ../data/IndividualData/lawler-data/10.20/afternoon_2hr33min/10.20.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.959490861166025  Recall:  0.5381844380403458 AUC 0.7594911987979102\n",
      "Test Accuracy: 0.95949\n",
      "Recall Accuracy: 0.53818\n",
      "AUC Score: 0.75949\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9518607151527764  Recall:  0.0 AUC 0.5\n",
      "Test Accuracy: 0.95186\n",
      "Recall Accuracy: 0.0\n",
      "AUC Score: 0.5\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.950889605660181  Recall:  0.012968299711815562 AUC 0.5056461101401125\n",
      "Test Accuracy: 0.95089\n",
      "Recall Accuracy: 0.01297\n",
      "AUC Score: 0.50565\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/shaurya-data/11.1.2020/Data.shm\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9771015987622486  Recall:  0.5254237288135594 AUC 0.7598213815890943\n",
      "Test Accuracy: 0.9771\n",
      "Recall Accuracy: 0.52542\n",
      "AUC Score: 0.75982\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9652398143372872  Recall:  0.17796610169491525 AUC 0.5865207877064662\n",
      "Test Accuracy: 0.96524\n",
      "Recall Accuracy: 0.17797\n",
      "AUC Score: 0.58652\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9671995874161939  Recall:  0.5310734463276836 AUC 0.7574005493066531\n",
      "Test Accuracy: 0.9672\n",
      "Recall Accuracy: 0.53107\n",
      "AUC Score: 0.7574\n",
      "Loading Dataset ...\n",
      "Loading File:  ../data/ShimmerData/P2396/P2396.shm\n",
      "Loading File:  ../data/ShimmerData/P2398/P2398.shm\n",
      "Loading File:  ../data/ShimmerData/P2399/P2399.shm\n",
      "Loading File:  ../data/ShimmerData/P2401/P2401.shm\n",
      "Loading File:  ../data/ShimmerData/P2402/P2402.shm\n",
      "Loading File:  ../data/ShimmerData/P2403/P2403.shm\n",
      "Loading File:  ../data/ShimmerData/P2406/P2406.shm\n",
      "Loading File:  ../data/ShimmerData/P2407/P2407.shm\n",
      "Loading File:  ../data/ShimmerData/P2408/P2408.shm\n",
      "Loading File:  ../data/ShimmerData/P2409/P2409.shm\n",
      "Loading File:  ../data/ShimmerData/P2410/P2410.shm\n",
      "Loading File:  ../data/ShimmerData/P2413/P2413.shm\n",
      "Loading File:  ../data/ShimmerData/P2415/P2415.shm\n",
      "Loading File:  ../data/ShimmerData/P2416/P2416.shm\n",
      "Loading File:  ../data/ShimmerData/P2417/P2417.shm\n",
      "Loading File:  ../data/ShimmerData/P2418/P2418.shm\n",
      "Loading File:  ../data/ShimmerData/P2419/P2419.shm\n",
      "Loading File:  ../data/ShimmerData/P2421/P2421.shm\n",
      "Loading File:  ../data/ShimmerData/P2422/P2422.shm\n",
      "Loading File:  ../data/ShimmerData/P2423/P2423.shm\n",
      "Loading File:  ../data/ShimmerData/P2424/P2424.shm\n",
      "Loading File:  ../data/ShimmerData/P2425/P2425.shm\n",
      "Loading File:  ../data/ShimmerData/P2426/P2426.shm\n",
      "Loading File:  ../data/ShimmerData/P2427/P2427.shm\n",
      "Loading File:  ../data/ShimmerData/P2428/P2428.shm\n",
      "Loading File:  ../data/ShimmerData/P2429/P2429.shm\n",
      "Loading File:  ../data/ShimmerData/P2430/P2430.shm\n",
      "Loading File:  ../data/ShimmerData/P2432/P2432.shm\n",
      "Loading File:  ../data/ShimmerData/P2434/P2434.shm\n",
      "Loading File:  ../data/ShimmerData/P2436/P2436.shm\n",
      "Loading File:  ../data/ShimmerData/P2437/P2437.shm\n",
      "Loading File:  ../data/ShimmerData/P2438/P2438.shm\n",
      "Loading File:  ../data/ShimmerData/P2440/P2440.shm\n",
      "Loading File:  ../data/ShimmerData/P2442/P2442.shm\n",
      "Loading File:  ../data/ShimmerData/P2443/P2443.shm\n",
      "Loading File:  ../data/ShimmerData/P2444/P2444.shm\n",
      "Loading File:  ../data/ShimmerData/P2446/P2446.shm\n",
      "Loading File:  ../data/ShimmerData/P2447/P2447.shm\n",
      "Loading File:  ../data/ShimmerData/P2449/P2449.shm\n",
      "Loading File:  ../data/ShimmerData/P2451/P2451.shm\n",
      "Loading File:  ../data/ShimmerData/P2452/P2452.shm\n",
      "Loading File:  ../data/ShimmerData/P2453/P2453.shm\n",
      "Loading File:  ../data/ShimmerData/P2454/P2454.shm\n",
      "Loading File:  ../data/ShimmerData/P2455/P2455.shm\n",
      "Loading File:  ../data/ShimmerData/P2456/P2456.shm\n",
      "Loading File:  ../data/ShimmerData/P2457/P2457.shm\n",
      "Loading File:  ../data/ShimmerData/P2458/P2458.shm\n",
      "Loading File:  ../data/ShimmerData/P2459/P2459.shm\n",
      "Loading File:  ../data/ShimmerData/P2460/P2460.shm\n",
      "Loading File:  ../data/ShimmerData/P2461/P2461.shm\n",
      "Loading File:  ../data/ShimmerData/P2462/P2462.shm\n",
      "Loading File:  ../data/ShimmerData/P2463/P2463.shm\n",
      "Loading File:  ../data/ShimmerData/P2464/P2464.shm\n",
      "Loading File:  ../data/ShimmerData/P2465/P2465.shm\n",
      "Loading File:  ../data/ShimmerData/P2466/P2466.shm\n",
      "Loading File:  ../data/ShimmerData/P2467/P2467.shm\n",
      "Loading File:  ../data/ShimmerData/P2468/P2468.shm\n",
      "Loading File:  ../data/ShimmerData/P2469/P2469.shm\n",
      "Loading File:  ../data/ShimmerData/P2470/P2470.shm\n",
      "Loading File:  ../data/ShimmerData/P2471/P2471.shm\n",
      "Loading File:  ../data/ShimmerData/P2474/P2474.shm\n",
      "Loading File:  ../data/ShimmerData/P2475/P2475.shm\n",
      "Loading File:  ../data/ShimmerData/P2476/P2476.shm\n",
      "Loading File:  ../data/ShimmerData/P2477/P2477.shm\n",
      "Loading File:  ../data/ShimmerData/P2478/P2478.shm\n",
      "Loading File:  ../data/ShimmerData/P2479/P2479.shm\n",
      "Loading File:  ../data/ShimmerData/P2481/P2481.shm\n",
      "Loading File:  ../data/ShimmerData/P2482/P2482.shm\n",
      "Loading File:  ../data/ShimmerData/P2483/P2483.shm\n",
      "Loading File:  ../data/ShimmerData/P2484/P2484.shm\n",
      "Test Accuracy: None\n",
      "Recall Accuracy: None\n",
      "AUC Score: None\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "Day:  4\n",
      "Segmentation Completed. \n",
      "Day:  5\n",
      "Segmentation Completed. \n",
      "Day:  6\n",
      "Segmentation Completed. \n",
      "Day:  7\n",
      "Segmentation Completed. \n",
      "Day:  8\n",
      "Segmentation Completed. \n",
      "Day:  9\n",
      "Segmentation Completed. \n",
      "Day:  10\n",
      "Segmentation Completed. \n",
      "Day:  11\n",
      "Segmentation Completed. \n",
      "Day:  12\n",
      "Segmentation Completed. \n",
      "Day:  13\n",
      "Segmentation Completed. \n",
      "Day:  14\n",
      "Segmentation Completed. \n",
      "Day:  15\n",
      "Segmentation Completed. \n",
      "Day:  16\n",
      "Segmentation Completed. \n",
      "Day:  17\n",
      "Segmentation Completed. \n",
      "Day:  18\n",
      "Segmentation Completed. \n",
      "Day:  19\n",
      "Segmentation Completed. \n",
      "Day:  20\n",
      "Segmentation Completed. \n",
      "Day:  21\n",
      "Segmentation Completed. \n",
      "Day:  22\n",
      "Segmentation Completed. \n",
      "Day:  23\n",
      "Segmentation Completed. \n",
      "Day:  24\n",
      "Segmentation Completed. \n",
      "Day:  25\n",
      "Segmentation Completed. \n",
      "Day:  26\n",
      "Segmentation Completed. \n",
      "Day:  27\n",
      "Segmentation Completed. \n",
      "Day:  28\n",
      "Segmentation Completed. \n",
      "Day:  29\n",
      "Segmentation Completed. \n",
      "Day:  30\n",
      "Segmentation Completed. \n",
      "Day:  31\n",
      "Segmentation Completed. \n",
      "Day:  32\n",
      "Segmentation Completed. \n",
      "Day:  33\n",
      "Segmentation Completed. \n",
      "Day:  34\n",
      "Segmentation Completed. \n",
      "Day:  35\n",
      "Segmentation Completed. \n",
      "Day:  36\n",
      "Segmentation Completed. \n",
      "Day:  37\n",
      "Segmentation Completed. \n",
      "Day:  38\n",
      "Segmentation Completed. \n",
      "Day:  39\n",
      "Segmentation Completed. \n",
      "Day:  40\n",
      "Segmentation Completed. \n",
      "Day:  41\n",
      "Segmentation Completed. \n",
      "Day:  42\n",
      "Segmentation Completed. \n",
      "Day:  43\n",
      "Segmentation Completed. \n",
      "Day:  44\n",
      "Segmentation Completed. \n",
      "Day:  45\n",
      "Segmentation Completed. \n",
      "Day:  46\n",
      "Segmentation Completed. \n",
      "Day:  47\n",
      "Segmentation Completed. \n",
      "Day:  48\n",
      "Segmentation Completed. \n",
      "Day:  49\n",
      "Segmentation Completed. \n",
      "Day:  50\n",
      "Segmentation Completed. \n",
      "Day:  51\n",
      "Segmentation Completed. \n",
      "Day:  52\n",
      "Segmentation Completed. \n",
      "Day:  53\n",
      "Segmentation Completed. \n",
      "Day:  54\n",
      "Segmentation Completed. \n",
      "Day:  55\n",
      "Segmentation Completed. \n",
      "Day:  56\n",
      "Segmentation Completed. \n",
      "Day:  57\n",
      "Segmentation Completed. \n",
      "Day:  58\n",
      "Segmentation Completed. \n",
      "Day:  59\n",
      "Segmentation Completed. \n",
      "Day:  60\n",
      "Segmentation Completed. \n",
      "Day:  61\n",
      "Segmentation Completed. \n",
      "Day:  62\n",
      "Segmentation Completed. \n",
      "Day:  63\n",
      "Segmentation Completed. \n",
      "Day:  64\n",
      "Segmentation Completed. \n",
      "Day:  65\n",
      "Segmentation Completed. \n",
      "Day:  66\n",
      "Segmentation Completed. \n",
      "Day:  67\n",
      "Segmentation Completed. \n",
      "Day:  68\n",
      "Segmentation Completed. \n",
      "Day:  69\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9545247654259381  Recall:  0.4907729708823692 AUC 0.7360760793827018\n",
      "Test Accuracy: 0.95452\n",
      "Recall Accuracy: 0.49077\n",
      "AUC Score: 0.73608\n",
      "Day:  0\n",
      "Segmentation Completed. \n",
      "Day:  1\n",
      "Segmentation Completed. \n",
      "Day:  2\n",
      "Segmentation Completed. \n",
      "Day:  3\n",
      "Segmentation Completed. \n",
      "Day:  4\n",
      "Segmentation Completed. \n",
      "Day:  5\n",
      "Segmentation Completed. \n",
      "Day:  6\n",
      "Segmentation Completed. \n",
      "Day:  7\n",
      "Segmentation Completed. \n",
      "Day:  8\n",
      "Segmentation Completed. \n",
      "Day:  9\n",
      "Segmentation Completed. \n",
      "Day:  10\n",
      "Segmentation Completed. \n",
      "Day:  11\n",
      "Segmentation Completed. \n",
      "Day:  12\n",
      "Segmentation Completed. \n",
      "Day:  13\n",
      "Segmentation Completed. \n",
      "Day:  14\n",
      "Segmentation Completed. \n",
      "Day:  15\n",
      "Segmentation Completed. \n",
      "Day:  16\n",
      "Segmentation Completed. \n",
      "Day:  17\n",
      "Segmentation Completed. \n",
      "Day:  18\n",
      "Segmentation Completed. \n",
      "Day:  19\n",
      "Segmentation Completed. \n",
      "Day:  20\n",
      "Segmentation Completed. \n",
      "Day:  21\n",
      "Segmentation Completed. \n",
      "Day:  22\n",
      "Segmentation Completed. \n",
      "Day:  23\n",
      "Segmentation Completed. \n",
      "Day:  24\n",
      "Segmentation Completed. \n",
      "Day:  25\n",
      "Segmentation Completed. \n",
      "Day:  26\n",
      "Segmentation Completed. \n",
      "Day:  27\n",
      "Segmentation Completed. \n",
      "Day:  28\n",
      "Segmentation Completed. \n",
      "Day:  29\n",
      "Segmentation Completed. \n",
      "Day:  30\n",
      "Segmentation Completed. \n",
      "Day:  31\n",
      "Segmentation Completed. \n",
      "Day:  32\n",
      "Segmentation Completed. \n",
      "Day:  33\n",
      "Segmentation Completed. \n",
      "Day:  34\n",
      "Segmentation Completed. \n",
      "Day:  35\n",
      "Segmentation Completed. \n",
      "Day:  36\n",
      "Segmentation Completed. \n",
      "Day:  37\n",
      "Segmentation Completed. \n",
      "Day:  38\n",
      "Segmentation Completed. \n",
      "Day:  39\n",
      "Segmentation Completed. \n",
      "Day:  40\n",
      "Segmentation Completed. \n",
      "Day:  41\n",
      "Segmentation Completed. \n",
      "Day:  42\n",
      "Segmentation Completed. \n",
      "Day:  43\n",
      "Segmentation Completed. \n",
      "Day:  44\n",
      "Segmentation Completed. \n",
      "Day:  45\n",
      "Segmentation Completed. \n",
      "Day:  46\n",
      "Segmentation Completed. \n",
      "Day:  47\n",
      "Segmentation Completed. \n",
      "Day:  48\n",
      "Segmentation Completed. \n",
      "Day:  49\n",
      "Segmentation Completed. \n",
      "Day:  50\n",
      "Segmentation Completed. \n",
      "Day:  51\n",
      "Segmentation Completed. \n",
      "Day:  52\n",
      "Segmentation Completed. \n",
      "Day:  53\n",
      "Segmentation Completed. \n",
      "Day:  54\n",
      "Segmentation Completed. \n",
      "Day:  55\n",
      "Segmentation Completed. \n",
      "Day:  56\n",
      "Segmentation Completed. \n",
      "Day:  57\n",
      "Segmentation Completed. \n",
      "Day:  58\n",
      "Segmentation Completed. \n",
      "Day:  59\n",
      "Segmentation Completed. \n",
      "Day:  60\n",
      "Segmentation Completed. \n",
      "Day:  61\n",
      "Segmentation Completed. \n",
      "Day:  62\n",
      "Segmentation Completed. \n",
      "Day:  63\n",
      "Segmentation Completed. \n",
      "Day:  64\n",
      "Segmentation Completed. \n",
      "Day:  65\n",
      "Segmentation Completed. \n",
      "Day:  66\n",
      "Segmentation Completed. \n",
      "Day:  67\n",
      "Segmentation Completed. \n",
      "Day:  68\n",
      "Segmentation Completed. \n",
      "Day:  69\n",
      "Segmentation Completed. \n",
      "All Days:   Accuracy:  0.9489630352106819  Recall:  0.4768495496988784 AUC 0.7265756034275866\n",
      "Test Accuracy: 0.94896\n",
      "Recall Accuracy: 0.47685\n",
      "AUC Score: 0.72658\n"
     ]
    }
   ],
   "source": [
    "threshold = {'wenkanw':[0.95, 0.45], 'adam':[0.95,0.45],'lawler':[0.95,0.45], 'shaurya':[0.95,0.45],'CAD':[0.95,0.45]}\n",
    "perf = test_models_hysteresis_threshold(names= [\"wenkanw\",\"adam\",\"lawler\",\"shaurya\",\"CAD\"],random_seed=1000, test_day=True, thresholds= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>win(sec)</th>\n",
       "      <th>Acc: Individual-Model</th>\n",
       "      <th>Recall: Individual-Model</th>\n",
       "      <th>Auc: Individual-Model</th>\n",
       "      <th>Acc: W-GroupModel</th>\n",
       "      <th>Recall: W-GroupModel</th>\n",
       "      <th>Auc: W-GroupModel</th>\n",
       "      <th>Acc: S-GroupModel</th>\n",
       "      <th>Recall: S-GroupModel</th>\n",
       "      <th>Auc: S-GroupModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenkanw</td>\n",
       "      <td>60</td>\n",
       "      <td>0.93432</td>\n",
       "      <td>0.96737</td>\n",
       "      <td>0.95011</td>\n",
       "      <td>0.95855</td>\n",
       "      <td>0.03963</td>\n",
       "      <td>0.51940</td>\n",
       "      <td>0.96102</td>\n",
       "      <td>0.12471</td>\n",
       "      <td>0.56135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>0.98204</td>\n",
       "      <td>0.85029</td>\n",
       "      <td>0.91801</td>\n",
       "      <td>0.97776</td>\n",
       "      <td>0.35125</td>\n",
       "      <td>0.67326</td>\n",
       "      <td>0.97860</td>\n",
       "      <td>0.33973</td>\n",
       "      <td>0.66809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawler</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95949</td>\n",
       "      <td>0.53818</td>\n",
       "      <td>0.75949</td>\n",
       "      <td>0.95186</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.95089</td>\n",
       "      <td>0.01297</td>\n",
       "      <td>0.50565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>60</td>\n",
       "      <td>0.97710</td>\n",
       "      <td>0.52542</td>\n",
       "      <td>0.75982</td>\n",
       "      <td>0.96524</td>\n",
       "      <td>0.17797</td>\n",
       "      <td>0.58652</td>\n",
       "      <td>0.96720</td>\n",
       "      <td>0.53107</td>\n",
       "      <td>0.75740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAD</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95452</td>\n",
       "      <td>0.49077</td>\n",
       "      <td>0.73608</td>\n",
       "      <td>0.94896</td>\n",
       "      <td>0.47685</td>\n",
       "      <td>0.72658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  win(sec)  Acc: Individual-Model  Recall: Individual-Model  \\\n",
       "0  wenkanw        60                0.93432                   0.96737   \n",
       "1     adam        60                0.98204                   0.85029   \n",
       "2   lawler        60                0.95949                   0.53818   \n",
       "3  shaurya        60                0.97710                   0.52542   \n",
       "4      CAD        60                    NaN                       NaN   \n",
       "\n",
       "   Auc: Individual-Model  Acc: W-GroupModel  Recall: W-GroupModel  \\\n",
       "0                0.95011            0.95855               0.03963   \n",
       "1                0.91801            0.97776               0.35125   \n",
       "2                0.75949            0.95186               0.00000   \n",
       "3                0.75982            0.96524               0.17797   \n",
       "4                    NaN            0.95452               0.49077   \n",
       "\n",
       "   Auc: W-GroupModel  Acc: S-GroupModel  Recall: S-GroupModel  \\\n",
       "0            0.51940            0.96102               0.12471   \n",
       "1            0.67326            0.97860               0.33973   \n",
       "2            0.50000            0.95089               0.01297   \n",
       "3            0.58652            0.96720               0.53107   \n",
       "4            0.73608            0.94896               0.47685   \n",
       "\n",
       "   Auc: S-GroupModel  \n",
       "0            0.56135  \n",
       "1            0.66809  \n",
       "2            0.50565  \n",
       "3            0.75740  \n",
       "4            0.72658  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "# import ipywidgets as widgets\n",
    "# def f(x):\n",
    "#     return x\n",
    "# interact(f, x=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv_v2",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
