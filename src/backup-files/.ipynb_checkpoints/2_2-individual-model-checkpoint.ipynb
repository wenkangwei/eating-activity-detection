{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Individual Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda Device Count:  2 Device Name:  Tesla V100-PCIE-16GB\n",
      "Torch version: 1.7.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from dataset import create_train_test_file_list, Person_MealsDataset, balance_data_indices\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device: \",device,\"Device Count: \", torch.cuda.device_count(), \"Device Name: \",torch.cuda.get_device_name()  )\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "### imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Turn off TensorFlow logging\n",
    "import tensorflow.compat.v1 as tf # maintain compatibility with TensorFlow 2.2.0\n",
    "\n",
    "import keras\n",
    "# from tensorflow.compat.v1.keras import backend as K # changed for compatibility with TensorFlow 2.2.0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "import loadfile\n",
    "import addons\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1\n",
    "from keras.models import load_model, save_model\n",
    "\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "shimmer_global_mean = [-0.012359981,-0.0051663737,0.011612018,\n",
    "                        0.05796114,0.1477952,-0.034395125 ]\n",
    "\n",
    "shimmer_global_stddev = [0.05756385,0.040893298,0.043825723,\n",
    "                        17.199743,15.311142,21.229317 ]\n",
    "\n",
    "shimmer_trended_mean = [-0.000002,-0.000002,-0.000000,\n",
    "                0.058144,0.147621,-0.033260 ]\n",
    "\n",
    "shimmer_trended_stddev = [0.037592,0.034135,0.032263,\n",
    "                17.209038,15.321441,21.242532 ]\n",
    "\n",
    "all_zero_means = [0,0,0,0,0,0]\n",
    "\n",
    "meanvals = all_zero_means\n",
    "stdvals = shimmer_trended_stddev\n",
    "\n",
    "\n",
    "random_seed  = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load my models and functions\n",
    "from dataset import create_train_test_file_list, Person_MealsDataset, balance_data_indices\n",
    "from utils import *\n",
    "from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "\n",
      "Execution Started at 12/20/2020, 19:58:59\n",
      "WindowLength: 3.00 min (2700 datum)\tSlide: 15 (225 datum)\tEpochs:30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "winmin = 3 \n",
    "stridesec = 15\n",
    "\n",
    "print_settings(winmin,stridesec, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ...\n",
      "Loading File:  ../data/IndividualData/adam-data/09-22-2020/09-22-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/10-28-2020/10-28-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-09-2020/11-09-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-11-2020/11-11-2020-1.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-12-2020/11-12-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-16-2020/11-16-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-17-2020/11-17-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-24-2020/11-24-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-25-2020/11-25-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-26-2020/11-26-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/11-30-2020/11-30-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-01-2020/12-01-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-02-2020/12-02-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-03-2020/12-03-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-04-2020/12-04-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-07-2020/12-07-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-08-2020/12-08-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-09-2020/12-09-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-10-2020/12-10-2020.shm\n",
      "Loading File:  ../data/IndividualData/adam-data/12-11-2020/12-11-2020.shm\n",
      "Train set size: 32253, with 887 positive samples and 31366 negative samples\n",
      "Test set size: 8064, with 222 positive samples and 7842 negative samples\n"
     ]
    }
   ],
   "source": [
    "person = \"adam\"\n",
    "meal_data = Person_MealsDataset(person_name= person, file_name = \"all_files_list\", winmin = winmin,stridesec = stridesec)\n",
    "samples,labels =  meal_data.data_indices, meal_data.labels\n",
    "# split train set and test set\n",
    "train_indices, test_indices = split_train_test_indices(X= [i for i in range(len(labels))],\n",
    "                                                        y = labels, test_size = 0.2,\n",
    "                                                       random_seed = random_seed)\n",
    "# balance train set\n",
    "trainset_labels = labels[train_indices]\n",
    "train_indices_balanced = balance_data_indices(trainset_labels,data_indices= train_indices,mode=\"under\", shuffle=True,random_state = random_seed,replace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loader Created\n"
     ]
    }
   ],
   "source": [
    "train_set_balanced = torch.utils.data.Subset(meal_data, train_indices_balanced)\n",
    "test_set = torch.utils.data.Subset(meal_data, test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set_balanced,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set ,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "print(\"Data Loader Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1419, with 709 positive samples and 710 negative samples\n",
      "Test set size: 355, with 178 positive samples and 177 negative samples\n",
      "Training set batch amounts: 14\n",
      "Test set : 3\n",
      "Start Training..\n",
      "Epoch: 0,  Epoch_Loss: 2.6186, Train Acc: 56.7644 %, Train Recall: 0.5242, Validation Acc:  64.7887 %,  Validation Recall: 0.4326  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 1,  Epoch_Loss: 0.7890, Train Acc: 68.0947 %, Train Recall: 0.7001, Validation Acc:  76.0563 %,  Validation Recall: 0.7978  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 2,  Epoch_Loss: 0.4662, Train Acc: 77.7339 %, Train Recall: 0.7756, Validation Acc:  73.8028 %,  Validation Recall: 0.6011  \n",
      "\n",
      "\n",
      "Epoch: 3,  Epoch_Loss: 0.3800, Train Acc: 83.5400 %, Train Recall: 0.8568, Validation Acc:  72.6761 %,  Validation Recall: 0.5449  \n",
      "\n",
      "\n",
      "Epoch: 4,  Epoch_Loss: 0.3322, Train Acc: 86.5840 %, Train Recall: 0.8760, Validation Acc:  83.9437 %,  Validation Recall: 0.7978  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 5,  Epoch_Loss: 0.3214, Train Acc: 87.5423 %, Train Recall: 0.9177, Validation Acc:  85.9155 %,  Validation Recall: 0.8483  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 6,  Epoch_Loss: 0.3167, Train Acc: 87.6550 %, Train Recall: 0.9109, Validation Acc:  85.6338 %,  Validation Recall: 0.8371  \n",
      "\n",
      "\n",
      "Epoch: 7,  Epoch_Loss: 0.3062, Train Acc: 88.1060 %, Train Recall: 0.9008, Validation Acc:  87.3239 %,  Validation Recall: 0.8708  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 8,  Epoch_Loss: 0.3056, Train Acc: 87.9369 %, Train Recall: 0.9030, Validation Acc:  87.8873 %,  Validation Recall: 0.8820  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 9,  Epoch_Loss: 0.3031, Train Acc: 88.3878 %, Train Recall: 0.9154, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "Checkpoint Saved\n",
      "\n",
      "\n",
      "Epoch: 10,  Epoch_Loss: 0.3013, Train Acc: 88.8388 %, Train Recall: 0.9200, Validation Acc:  87.8873 %,  Validation Recall: 0.8820  \n",
      "\n",
      "\n",
      "Epoch: 11,  Epoch_Loss: 0.2986, Train Acc: 88.6133 %, Train Recall: 0.9211, Validation Acc:  87.3239 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 12,  Epoch_Loss: 0.2999, Train Acc: 88.2187 %, Train Recall: 0.9098, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 13,  Epoch_Loss: 0.3023, Train Acc: 88.3315 %, Train Recall: 0.9143, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 14,  Epoch_Loss: 0.2972, Train Acc: 89.1770 %, Train Recall: 0.9233, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 15,  Epoch_Loss: 0.2988, Train Acc: 88.7824 %, Train Recall: 0.9177, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 16,  Epoch_Loss: 0.2995, Train Acc: 88.1623 %, Train Recall: 0.9087, Validation Acc:  87.3239 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 17,  Epoch_Loss: 0.3005, Train Acc: 88.1060 %, Train Recall: 0.9098, Validation Acc:  87.3239 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 18,  Epoch_Loss: 0.2988, Train Acc: 89.1770 %, Train Recall: 0.9245, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 19,  Epoch_Loss: 0.3017, Train Acc: 88.2751 %, Train Recall: 0.9143, Validation Acc:  87.8873 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 20,  Epoch_Loss: 0.2967, Train Acc: 89.0643 %, Train Recall: 0.9188, Validation Acc:  87.3239 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 21,  Epoch_Loss: 0.3007, Train Acc: 88.6697 %, Train Recall: 0.9200, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 22,  Epoch_Loss: 0.3032, Train Acc: 88.3315 %, Train Recall: 0.9188, Validation Acc:  87.6056 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 23,  Epoch_Loss: 0.2994, Train Acc: 88.9515 %, Train Recall: 0.9121, Validation Acc:  87.8873 %,  Validation Recall: 0.8820  \n",
      "\n",
      "\n",
      "Epoch: 24,  Epoch_Loss: 0.2979, Train Acc: 88.2751 %, Train Recall: 0.9121, Validation Acc:  87.8873 %,  Validation Recall: 0.8820  \n",
      "\n",
      "\n",
      "Epoch: 25,  Epoch_Loss: 0.2984, Train Acc: 88.4442 %, Train Recall: 0.9166, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 26,  Epoch_Loss: 0.3044, Train Acc: 88.3315 %, Train Recall: 0.9154, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 27,  Epoch_Loss: 0.2995, Train Acc: 88.9515 %, Train Recall: 0.9177, Validation Acc:  87.6056 %,  Validation Recall: 0.8764  \n",
      "\n",
      "\n",
      "Epoch: 28,  Epoch_Loss: 0.3027, Train Acc: 88.4442 %, Train Recall: 0.9143, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Epoch: 29,  Epoch_Loss: 0.2992, Train Acc: 88.6133 %, Train Recall: 0.9211, Validation Acc:  88.1690 %,  Validation Recall: 0.8876  \n",
      "\n",
      "\n",
      "Load Best Model.\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# split validation set\n",
    "balanced_trainset_labels = labels[train_indices_balanced]\n",
    "train_indices, valid_indices = split_train_test_indices(X= train_indices_balanced,\n",
    "                                                        y = balanced_trainset_labels, test_size = 0.2,\n",
    "                                                       random_seed = random_seed)\n",
    "\n",
    "valid_set_balanced = torch.utils.data.Subset(meal_data, valid_indices)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set_balanced,batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "# train model\n",
    "input_shape = (train_set_balanced[0][0].shape[0], train_set_balanced[0][0].shape[1])\n",
    "model_1 = Discriminator_ResNet( ngpu=1, input_shape =input_shape , out_fea = 1)\n",
    "_ = model_1(torch.rand((1, input_shape[0],input_shape[1])))\n",
    "model_1.to(device)\n",
    "criterion_1 = nn.BCEWithLogitsLoss()\n",
    "optimizer_1 = optim.Adam(model_1.parameters(),lr=0.01,  weight_decay=0.1)\n",
    "lrscheduler_1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer_1, mode='min',patience= 2, factor = 0.1,threshold=0.01)\n",
    "dataloader = (train_loader, valid_loader)\n",
    "model_1, best_model_1,val_score_1,loss_ls_1, train_acc_ls_1, valid_acc_ls_1 = train_model(model_1,dataloader, optimizer_1, \n",
    "                                                                    criterion_1, lrscheduler_1, device= device,\n",
    "                                                                    n_epochs=30, patience = 5, l1_enabled=False,\n",
    "                                                                    checkpoint_name =\"../models/adam_models/checkpoint_model_resnet.pt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.53174603174604\n"
     ]
    }
   ],
   "source": [
    "best_model_1.eval()\n",
    "acc, recall = eval_model(best_model_1, test_loader,device)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check if random generated indices can be reproducted\n",
    "# ls = balance_data_indices(traininglabels,mode=\"under\", shuffle=True,random_state = random_seed)\n",
    "# ls ==train_shuffledUnderSampledBalancedIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
